{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9egyhuvU3_GI"
   },
   "source": [
    "## SI 650 / EECS 549: Homework 3 Part 2\n",
    "\n",
    "Homework 3 Part 2 will have you working with deep learning models in a variety of ways. You will likely need to run this on Great Lakes unless you have access to a GPU elsewhere (or be prepared to wait a long time). You should have completed Parts 1 and 2 before attempting this notebook to familiarize yourself with how PyTerrier works.\n",
    "\n",
    "In Part 3, you'll try the following tasks:\n",
    " - Use a large language model to re-rank content\n",
    " - Use a text-to-text model to perform query augmentation\n",
    " - Train a deep learning IR model and compare its performance.\n",
    " \n",
    "The first two of these tasks will rely on models that we've pretrained for you. However, we've also provided code for how to train these. In the third task, you'll do one simple training in evaluate.\n",
    "\n",
    "For the first two tasks, we've provided most of the code. *You are expected to submit results showing that you have successfully executed it*. You'll need to understand some of the code to complete task 3, which requires you to write new code.\n",
    "\n",
    "As with the past notebooks, you'll need to have `JAVA_HOME` set, which will need to be run on Great Lakes. You can potentially set it in the notebook with a Jupyter command like\n",
    "```\n",
    "!export JAVA_HOME=/fill/in/the/path/to/the/JDK/here\n",
    "```\n",
    "by first figuring out where the JDK is installed. (This is setting the `JAVA_HOME` environment variable in the unix way). \n",
    "\n",
    "You can work on Parts 1 and 2 separately, so feel free to do the GPU-part (Part 2) when the resources are available on Great Lakes and the non-GPU part on your laptop or on a non-GPU Great Lakes machine (which likely will be much faster). Note that there will be no extensions due to Great Lakes bottlenecks, so you are encouraged to complete Part 2 as soon as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV0C6jJvqhMR"
   },
   "source": [
    "### Install the PyTerrier extensions\n",
    "\n",
    "You'll need two extensions for [OpenNIR](https://opennir.net/) and [doc2query](https://github.com/terrierteam/pyterrier_doc2query). We've provided the package install commands in comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load openjdk\n",
    "# !load openjdk/11.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83109,
     "status": "ok",
     "timestamp": 1666981459298,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "AkIR_PXdet7R",
    "outputId": "14cecc5d-cf1b-4783-c726-10d2f32a2b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/Georgetown-IR-Lab/OpenNIR\n",
      "  Cloning https://github.com/Georgetown-IR-Lab/OpenNIR to /tmp/pip-req-build-glj3sdse\n",
      "  Running command git clone -q https://github.com/Georgetown-IR-Lab/OpenNIR /tmp/pip-req-build-glj3sdse\n",
      "  Resolved https://github.com/Georgetown-IR-Lab/OpenNIR to commit 88a4679372f471a04d284a99404ffce2b7a1dc49\n",
      "Requirement already satisfied: torch>=1.3.1 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (1.13.0)\n",
      "Requirement already satisfied: pytorch-pretrained-bert==0.6.1 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (0.6.1)\n",
      "Requirement already satisfied: pytorch-transformers==1.1.0 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: tokenizers>=0.1.1 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (0.13.1)\n",
      "Requirement already satisfied: transformers>=4.3.3 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (4.23.1)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (4.62.3)\n",
      "Requirement already satisfied: colorlog==4.0.2 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (4.0.2)\n",
      "Requirement already satisfied: terminaltables>=3.1.0 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (3.1.10)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (3.4.3)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (0.11.2)\n",
      "Requirement already satisfied: python-ternary>=1.0.6 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (1.0.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (4.10.0)\n",
      "Requirement already satisfied: html5lib>=1.0.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (1.1)\n",
      "Requirement already satisfied: Unidecode>=1.0.22 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: nltk>=3.4.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (3.6.5)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.1 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (0.5.5)\n",
      "Requirement already satisfied: gensim>=3.7.3 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (4.2.0)\n",
      "Requirement already satisfied: Cython>=0.29.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (0.29.24)\n",
      "Requirement already satisfied: pyjnius>=1.2.1 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: ir_datasets>=0.2.0 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (0.5.4)\n",
      "Requirement already satisfied: ir_measures>=0.2.1 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (0.3.1)\n",
      "Requirement already satisfied: pytools>=2018.5.2 in /home/yianchu/.local/lib/python3.9/site-packages (from OpenNIR==0.1.0) (2022.1.12)\n",
      "Requirement already satisfied: cached-property>=1.5.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from OpenNIR==0.1.0) (1.5.2)\n",
      "Requirement already satisfied: numpy in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (1.20.3)\n",
      "Requirement already satisfied: requests in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (2.26.0)\n",
      "Requirement already satisfied: regex in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (2021.8.3)\n",
      "Requirement already satisfied: boto3 in /home/yianchu/.local/lib/python3.9/site-packages (from pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (1.25.4)\n",
      "Requirement already satisfied: sentencepiece in /home/yianchu/.local/lib/python3.9/site-packages (from pytorch-transformers==1.1.0->OpenNIR==0.1.0) (0.1.97)\n",
      "Requirement already satisfied: soupsieve>1.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from beautifulsoup4>=4.9.3->OpenNIR==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from gensim>=3.7.3->OpenNIR==0.1.0) (1.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/yianchu/.local/lib/python3.9/site-packages (from gensim>=3.7.3->OpenNIR==0.1.0) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from html5lib>=1.0.1->OpenNIR==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from html5lib>=1.0.1->OpenNIR==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (0.2.3)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (0.2.1)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (0.2.5)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (0.1.9)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (2.6)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (3.1.4)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (0.1.5)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (6.0)\n",
      "Requirement already satisfied: lz4>=3.1.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (4.0.2)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ir_datasets>=0.2.0->OpenNIR==0.1.0) (4.6.3)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /home/yianchu/.local/lib/python3.9/site-packages (from ir_measures>=0.2.1->OpenNIR==0.1.0) (1.0.12)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>=3.0.2->OpenNIR==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>=3.0.2->OpenNIR==0.1.0) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>=3.0.2->OpenNIR==0.1.0) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>=3.0.2->OpenNIR==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>=3.0.2->OpenNIR==0.1.0) (0.10.0)\n",
      "Requirement already satisfied: click in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nltk>=3.4.5->OpenNIR==0.1.0) (8.0.3)\n",
      "Requirement already satisfied: joblib in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nltk>=3.4.5->OpenNIR==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /home/yianchu/.local/lib/python3.9/site-packages (from pytools>=2018.5.2->OpenNIR==0.1.0) (2.5.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /home/yianchu/.local/lib/python3.9/site-packages (from pytools>=2018.5.2->OpenNIR==0.1.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (2021.10.8)\n",
      "Requirement already satisfied: pandas>=0.23 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from seaborn>=0.9.0->OpenNIR==0.1.0) (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pandas>=0.23->seaborn>=0.9.0->OpenNIR==0.1.0) (2021.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/yianchu/.local/lib/python3.9/site-packages (from torch>=1.3.1->OpenNIR==0.1.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/yianchu/.local/lib/python3.9/site-packages (from torch>=1.3.1->OpenNIR==0.1.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/yianchu/.local/lib/python3.9/site-packages (from torch>=1.3.1->OpenNIR==0.1.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/yianchu/.local/lib/python3.9/site-packages (from torch>=1.3.1->OpenNIR==0.1.0) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3.1->OpenNIR==0.1.0) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3.1->OpenNIR==0.1.0) (58.0.4)\n",
      "Requirement already satisfied: filelock in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from transformers>=4.3.3->OpenNIR==0.1.0) (3.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from transformers>=4.3.3->OpenNIR==0.1.0) (21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/yianchu/.local/lib/python3.9/site-packages (from transformers>=4.3.3->OpenNIR==0.1.0) (0.10.1)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /home/yianchu/.local/lib/python3.9/site-packages (from trec-car-tools>=2.5.4->ir_datasets>=0.2.0->OpenNIR==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/yianchu/.local/lib/python3.9/site-packages (from boto3->pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.29.0,>=1.28.4 in /home/yianchu/.local/lib/python3.9/site-packages (from boto3->pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (1.28.4)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/yianchu/.local/lib/python3.9/site-packages (from boto3->pytorch-pretrained-bert==0.6.1->OpenNIR==0.1.0) (0.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/terrierteam/pyterrier_doc2query.git\n",
      "  Cloning https://github.com/terrierteam/pyterrier_doc2query.git to /tmp/pip-req-build-42dwmdjl\n",
      "  Running command git clone -q https://github.com/terrierteam/pyterrier_doc2query.git /tmp/pip-req-build-42dwmdjl\n",
      "  Resolved https://github.com/terrierteam/pyterrier_doc2query.git to commit 247242e04a8fa6476ad1487c393bda5db226705c\n",
      "Requirement already satisfied: python-terrier>=0.5.0 in /home/yianchu/.local/lib/python3.9/site-packages (from pyterrier-doc2query==0.0.1) (0.8.1)\n",
      "Requirement already satisfied: pandas in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pyterrier-doc2query==0.0.1) (1.3.4)\n",
      "Requirement already satisfied: transformers in /home/yianchu/.local/lib/python3.9/site-packages (from pyterrier-doc2query==0.0.1) (4.23.1)\n",
      "Requirement already satisfied: torch in /home/yianchu/.local/lib/python3.9/site-packages (from pyterrier-doc2query==0.0.1) (1.13.0)\n",
      "Requirement already satisfied: sentencepiece in /home/yianchu/.local/lib/python3.9/site-packages (from pyterrier-doc2query==0.0.1) (0.1.97)\n",
      "Requirement already satisfied: dill in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.3.6)\n",
      "Requirement already satisfied: statsmodels in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.12.2)\n",
      "Requirement already satisfied: sklearn in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.0)\n",
      "Requirement already satisfied: chest in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.2.3)\n",
      "Requirement already satisfied: requests in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2.26.0)\n",
      "Requirement already satisfied: matchpy in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.5.5)\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.5.4)\n",
      "Requirement already satisfied: wget in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (3.2)\n",
      "Requirement already satisfied: numpy in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.20.3)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.4.4)\n",
      "Requirement already satisfied: pyjnius~=1.3.0 in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: tqdm in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (4.62.3)\n",
      "Requirement already satisfied: joblib in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: ir-measures>=0.2.0 in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.3.1)\n",
      "Requirement already satisfied: scipy in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.7.1)\n",
      "Requirement already satisfied: more-itertools in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (8.10.0)\n",
      "Requirement already satisfied: jinja2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2.11.3)\n",
      "Requirement already satisfied: deprecation in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2.1.0)\n",
      "Requirement already satisfied: typish>=1.7.0 in /home/yianchu/.local/lib/python3.9/site-packages (from nptyping==1.4.4->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (6.0)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.2.3)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.1.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (4.10.0)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (3.1.4)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.2.5)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2.6)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.1.9)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.2.1)\n",
      "Requirement already satisfied: lz4>=3.1.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (4.0.2)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (4.6.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2.2.1)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.2 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-measures>=0.2.0->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.5.5)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-measures>=0.2.0->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.0.12)\n",
      "Requirement already satisfied: cython in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pyjnius~=1.3.0->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.29.24)\n",
      "Requirement already satisfied: six>=1.7.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pyjnius~=1.3.0->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.26.7)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /home/yianchu/.local/lib/python3.9/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from chest->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.0.1)\n",
      "Requirement already satisfied: packaging in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from deprecation->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (21.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jinja2->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (1.1.1)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /home/yianchu/.local/lib/python3.9/site-packages (from matchpy->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from packaging->deprecation->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pandas->pyterrier-doc2query==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pandas->pyterrier-doc2query==0.0.1) (2021.3)\n",
      "Requirement already satisfied: scikit-learn in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from sklearn->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from scikit-learn->sklearn->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from statsmodels->python-terrier>=0.5.0->pyterrier-doc2query==0.0.1) (0.5.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/yianchu/.local/lib/python3.9/site-packages (from torch->pyterrier-doc2query==0.0.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/yianchu/.local/lib/python3.9/site-packages (from torch->pyterrier-doc2query==0.0.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/yianchu/.local/lib/python3.9/site-packages (from torch->pyterrier-doc2query==0.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/yianchu/.local/lib/python3.9/site-packages (from torch->pyterrier-doc2query==0.0.1) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/yianchu/.local/lib/python3.9/site-packages (from torch->pyterrier-doc2query==0.0.1) (4.4.0)\n",
      "Requirement already satisfied: wheel in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->pyterrier-doc2query==0.0.1) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->pyterrier-doc2query==0.0.1) (58.0.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/yianchu/.local/lib/python3.9/site-packages (from transformers->pyterrier-doc2query==0.0.1) (0.10.1)\n",
      "Requirement already satisfied: filelock in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from transformers->pyterrier-doc2query==0.0.1) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from transformers->pyterrier-doc2query==0.0.1) (2021.8.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/yianchu/.local/lib/python3.9/site-packages (from transformers->pyterrier-doc2query==0.0.1) (0.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/Georgetown-IR-Lab/OpenNIR\n",
    "!pip install --upgrade git+https://github.com/terrierteam/pyterrier_doc2query.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3614,
     "status": "ok",
     "timestamp": 1666981487074,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "1TXDRNBwfatS",
    "outputId": "52c3cb5d-91b9-4188-d1d6-01b873e96a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-terrier in /home/yianchu/.local/lib/python3.9/site-packages (0.8.1)\n",
      "Requirement already satisfied: chest in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: deprecation in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (2.1.0)\n",
      "Requirement already satisfied: requests in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (2.26.0)\n",
      "Requirement already satisfied: pyjnius~=1.3.0 in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (1.3.0)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (0.5.4)\n",
      "Requirement already satisfied: numpy in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (1.20.3)\n",
      "Requirement already satisfied: pandas in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (1.3.4)\n",
      "Requirement already satisfied: more-itertools in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (8.10.0)\n",
      "Requirement already satisfied: scipy in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (1.7.1)\n",
      "Requirement already satisfied: dill in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (0.3.6)\n",
      "Requirement already satisfied: ir-measures>=0.2.0 in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (0.3.1)\n",
      "Requirement already satisfied: jinja2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (2.11.3)\n",
      "Requirement already satisfied: matchpy in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: statsmodels in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (0.12.2)\n",
      "Requirement already satisfied: tqdm in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (4.62.3)\n",
      "Requirement already satisfied: joblib in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-terrier) (1.1.0)\n",
      "Requirement already satisfied: sklearn in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (0.0)\n",
      "Requirement already satisfied: wget in /home/yianchu/.local/lib/python3.9/site-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: typish>=1.7.0 in /home/yianchu/.local/lib/python3.9/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (3.1.4)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.1)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.6.3)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.10.0)\n",
      "Requirement already satisfied: lz4>=3.1.1 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.0.2)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.5)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ir-datasets>=0.3.2->python-terrier) (6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.2.1)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-measures>=0.2.0->python-terrier) (1.0.12)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.2 in /home/yianchu/.local/lib/python3.9/site-packages (from ir-measures>=0.2.0->python-terrier) (0.5.5)\n",
      "Requirement already satisfied: cython in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pyjnius~=1.3.0->python-terrier) (0.29.24)\n",
      "Requirement already satisfied: six>=1.7.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pyjnius~=1.3.0->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->python-terrier) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->python-terrier) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->python-terrier) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->python-terrier) (3.2)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /home/yianchu/.local/lib/python3.9/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: packaging in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from deprecation->python-terrier) (21.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jinja2->python-terrier) (1.1.1)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /home/yianchu/.local/lib/python3.9/site-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from packaging->deprecation->python-terrier) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pandas->python-terrier) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pandas->python-terrier) (2021.3)\n",
      "Requirement already satisfied: scikit-learn in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from sklearn->python-terrier) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from scikit-learn->sklearn->python-terrier) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from statsmodels->python-terrier) (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-terrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-nQrpNP5pN7"
   },
   "source": [
    "## Getting started\n",
    "\n",
    "Start PyTerrier as we have in past notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1666943425118,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "U_ZpwBV1bD_Q",
    "outputId": "86b9c82c-241a-403f-9895-194c1460d612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/openjdk/jdk-18.0.1.1\r\n"
     ]
    }
   ],
   "source": [
    "# !export JAVA_HOME=/fill/in/the/path/to/the/JDK/here\n",
    "!echo $JAVA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1666981497487,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "ziHB21B8ZEJ5"
   },
   "outputs": [],
   "source": [
    "# !export JAVA_HOME=/usr/lib/jvm/java-17-oracle/\n",
    "import os\n",
    "# os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-17-oracle/'\n",
    "os.environ['JAVA_HOME'] = '/sw/pkgs/arc/openjdk/jdk-18.0.1.1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6,7'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17597,
     "status": "ok",
     "timestamp": 1666981517787,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "6FegcyWr5lja",
    "outputId": "317a5923-33f3-405b-8931-3c3d3739d3d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.8.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init(tqdm=\"notebook\")\n",
    "import onir_pt\n",
    "import pyterrier_doc2query\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPVjr448rIPc"
   },
   "source": [
    "### [TREC-COVID19](https://ir.nist.gov/covidSubmit/) Dataset download\n",
    "\n",
    "The following cell downloads the [TREC-COVID19](https://ir.nist.gov/covidSubmit/) dataset that we will use periodically throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5107,
     "status": "ok",
     "timestamp": 1666981528604,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "IJMHFRfArd7O",
    "outputId": "fee5fee6-11c7-457f-8223-8e614799edb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yianchu/.local/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "topics = dataset.get_topics(variant='description')\n",
    "qrels = dataset.get_qrels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF3HIPhtrqOH"
   },
   "source": [
    "# Task 1: Build the inverted index for the TREC-COVID19 collection (5 points)\n",
    "\n",
    "Build the index for the TREC Covid-19 (CORD19) data like we have in past notebooks but without any fancy options (e.g., no positional indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f69437f61cc049679f40e3f7d460063b",
      "bda29af558d3441aba1314ad63971f18",
      "f0c27da6a4564ca3978b62fa0a94ac01",
      "7a7a8edd8a5748b991cb14eda85e3456",
      "1763b73855a74aae9b887508d20d0cd1",
      "1334426445c84c0e83e73e2703b4d3ec",
      "68112ad488014d3c9e29a2ebf230ad27",
      "2320258836e246bab3ef337e449e3011",
      "5f2552cf4bff484e8fa267b316e5187c",
      "5b0c9e8cc35e494ebdce2b19da4fd529",
      "e0777ba7cc804e089cf3de10cb62c45b"
     ]
    },
    "executionInfo": {
     "elapsed": 114812,
     "status": "ok",
     "timestamp": 1666981860609,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "w_jJIv1dZEKx",
    "outputId": "fd8c0b6b-b34b-4197-bad5-e6457b5f3b11"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8be9c3bfe7241418f9ad4b7e9714a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cord19/trec-covid documents:   0%|          | 0/192509 [15ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1460897/2564545616.py:11: DeprecationWarning: specifying meta and meta_lengths in IterDictIndexer.index() is deprecated, use constructor instead\n",
      "  index_ref = indexer.index(cord19.get_corpus_iter(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:03:25.785 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (6iu1dtyl) - further warnings are suppressed\n",
      "02:04:19.589 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer - Indexed 54937 empty documents\n",
      "02:04:20.469 [ForkJoinPool-1-worker-1] ERROR org.terrier.structures.indexing.Indexer - Could not finish MetaIndexBuilder: \n",
      "java.io.IOException: Key 8lqzfj2e is not unique: 37597,11755\n",
      "For MetaIndex, to suppress, set metaindex.compressed.reverse.allow.duplicates=true\n",
      "\tat org.terrier.structures.collections.FSOrderedMapFile$MultiFSOMapWriter.mergeTwo(FSOrderedMapFile.java:1374)\n",
      "\tat org.terrier.structures.collections.FSOrderedMapFile$MultiFSOMapWriter.close(FSOrderedMapFile.java:1308)\n",
      "\tat org.terrier.structures.indexing.BaseMetaIndexBuilder.close(BaseMetaIndexBuilder.java:321)\n",
      "\tat org.terrier.structures.indexing.classical.BlockIndexer.createDirectIndex(BlockIndexer.java:472)\n",
      "\tat org.terrier.structures.indexing.Indexer.index(Indexer.java:369)\n",
      "\tat org.terrier.python.ParallelIndexer$1.apply(ParallelIndexer.java:63)\n",
      "\tat org.terrier.python.ParallelIndexer$1.apply(ParallelIndexer.java:52)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)\n",
      "\tat java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:992)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:960)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:934)\n",
      "\tat java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327)\n",
      "\tat java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:754)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:686)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:927)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)\n",
      "\tat java.base/java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:662)\n",
      "\tat org.terrier.python.ParallelIndexer$3.call(ParallelIndexer.java:133)\n",
      "\tat org.terrier.python.ParallelIndexer$3.call(ParallelIndexer.java:130)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1428)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)\n"
     ]
    }
   ],
   "source": [
    "cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "\n",
    "pt_index_path = './terrier_cord19'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "    # create the index, using the IterDictIndexer indexer \n",
    "    indexer = pt.index.IterDictIndexer(pt_index_path, blocks=True)\n",
    "\n",
    "    # we give the dataset get_corpus_iter() directly to the indexer\n",
    "    # while specifying the fields to index and the metadata to record\n",
    "    index_ref = indexer.index(cord19.get_corpus_iter(), \n",
    "                              fields=('abstract',), \n",
    "                              meta=('docno',))\n",
    "\n",
    "else:\n",
    "    # if you already have the index, use it.\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "# TODO: build the CORD19 index, and have it referenced as \"index\"\n",
    "# for the code in later cells to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwDams5M7g6c"
   },
   "source": [
    "## Using an untuned Re-rankers\n",
    "\n",
    "This notebook will have you work with few neural re-ranking methods that you've used in class. We can build them from scratch using `onir_pt.reranker` or load them from pretrained models. The models we load from scratch won't have been trained to do IR (yet), however.\n",
    "\n",
    "And OpenNIR reranking model consists of:\n",
    " - `ranker` (e.g., `drmm`, `knrm`, or `pacrr`). This defines the neural ranking architecture. We discussed the `knrm` approach in class.\n",
    " - `vocab` (e.g., `wordvec_hash`, or `bert`). This defines how text is encoded by the model. This approach makes it easy to swap out different text representations. \n",
    " \n",
    "Let's start with the `knrm` method we discussed in class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17444,
     "status": "ok",
     "timestamp": 1666981890120,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "F0O79K2K6fvn",
    "outputId": "572f93e7-905e-43c5-d4f7-8ba5fab10ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file not found: config\n",
      "[2022-11-01 02:04:28,622][WordvecHashVocab][DEBUG] [starting] reading cached at /home/yianchu/data/onir/vocab/wordvec_hash/fasttext-wiki-news-300d-1M.p\n",
      "[2022-11-01 02:04:29,983][WordvecHashVocab][DEBUG] [finished] reading cached at /home/yianchu/data/onir/vocab/wordvec_hash/fasttext-wiki-news-300d-1M.p [1.37s]\n"
     ]
    }
   ],
   "source": [
    "knrm = onir_pt.reranker('knrm', 'wordvec_hash', text_field='abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1avVTpxDORN"
   },
   "source": [
    "Let's look at how well this model work at ranking compared with our default `BatchRetrieve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166,
     "referenced_widgets": [
      "863e39b5666b4047a1c5bdb51328331b",
      "934d41cace5a432e9775261987f20777",
      "298015f6a4f94124923c87c647e7fac4",
      "d0b64a8ca745479e81c8282a528d369c",
      "51622d428af649de9418789d44d3c3d8",
      "03205af8db554ed8acfd285d9d8f3872",
      "420321132ab349eaa56fce49c87b05b4",
      "e5160c5a8f1c4d4a9cdb40a2fba834f6",
      "76ebb395c6e54586b8dfcf82531d8720",
      "ff10e5edb9264bf7b82884eea1cdd48c",
      "fef95649700b463981819d0b5dfacc9c"
     ]
    },
    "executionInfo": {
     "elapsed": 15672,
     "status": "ok",
     "timestamp": 1666981909749,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "4FWUIN577v1O",
    "outputId": "1695b361-7b7c-40cb-dafa-fb5afbcf33f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:04:40,430][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 02:04:40,432][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/1250 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:04:43,692][onir_pt][DEBUG] [finished] batches: [3.26s] [1250it] [383.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>P.10</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.068056</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.609058</td>\n",
       "      <td>0.658</td>\n",
       "      <td>61.876211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DPH &gt;&gt; KNRM</td>\n",
       "      <td>0.054809</td>\n",
       "      <td>0.145486</td>\n",
       "      <td>0.359992</td>\n",
       "      <td>0.450</td>\n",
       "      <td>118.679645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name       map      ndcg  ndcg_cut.10   P.10         mrt\n",
       "0          DPH  0.068056  0.165653     0.609058  0.658   61.876211\n",
       "1  DPH >> KNRM  0.054809  0.145486     0.359992  0.450  118.679645"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = pt.BatchRetrieve(index) % 100\n",
    "pipeline = br >> pt.text.get_text(dataset, 'abstract') >> knrm\n",
    "pt.Experiment(\n",
    "    [br, pipeline],\n",
    "    topics,\n",
    "    qrels,\n",
    "    names=['DPH', 'DPH >> KNRM'],\n",
    "    eval_metrics=[\"map\", \"ndcg\", 'ndcg_cut.10', 'P.10', 'mrt']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhquobQypVNJ"
   },
   "source": [
    "The `knrm` models' performance is lower! The mode doesn't work very well because it hasn't yet been trained for IR; it's using random weights to combine the scores from the similarity matrix--but this is at least a start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLv7quA43yAP"
   },
   "source": [
    "## Loading a trained re-ranker\n",
    "\n",
    "You can train re-ranking models in PyTerrier using the `fit` method. Here's an example of how to train the `knrm` model on the MS MARCO dataset, which is a large IR collection.\n",
    "\n",
    "```python\n",
    "# transfer training signals from a medical sample of MS MARCO\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_ds = pt.datasets.get_dataset('irds:msmarco-passage/train/medical')\n",
    "train_topics, valid_topics = train_test_split(train_ds.get_topics(), test_size=50, random_state=42) # split into training and validation sets\n",
    "\n",
    "# Index MS MARCO\n",
    "indexer = pt.index.IterDictIndexer('./terrier_msmarco-passage')\n",
    "tr_index_ref = indexer.index(train_ds.get_corpus_iter(), fields=('text',), meta=('docno',))\n",
    "\n",
    "pipeline = (pt.BatchRetrieve(tr_index_ref) % 100 # get top 100 results\n",
    "            >> pt.text.get_text(train_ds, 'text') # fetch the document text\n",
    "            >> pt.apply.generic(lambda df: df.rename(columns={'text': 'abstract'})) # rename columns\n",
    "            >> knrm) # apply neural re-ranker\n",
    "\n",
    "pipeline.fit(\n",
    "    train_topics,\n",
    "    train_ds.get_qrels(),\n",
    "    valid_topics,\n",
    "    train_ds.get_qrels())\n",
    "```\n",
    "\n",
    "Training deep learning models takes a bit of time (especially for large datasets like MS MARCO), so we've provided a model that's already been trained for you to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15166,
     "status": "ok",
     "timestamp": 1666982352229,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "Yk7FBOgvDa8V",
    "outputId": "47bc3e91-2f40-4774-c211-77ae1c6a9feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:04:43,828][onir_pt][INFO] using cached checkpoint: /home/yianchu/data/onir/model_checkpoints/b7694d2fb4d4f8218e11734de239ad30\n",
      "[2022-11-01 02:04:43,833][WordvecHashVocab][DEBUG] [starting] reading cached at /home/yianchu/data/onir/vocab/wordvec_hash/fasttext-wiki-news-300d-1M.p\n",
      "[2022-11-01 02:04:45,184][WordvecHashVocab][DEBUG] [finished] reading cached at /home/yianchu/data/onir/vocab/wordvec_hash/fasttext-wiki-news-300d-1M.p [1.35s]\n"
     ]
    }
   ],
   "source": [
    "del knrm # free up the memory before loading a new version of the ranker (helpful for the GPU)\n",
    "knrm = onir_pt.reranker.from_checkpoint('https://macavaney.us/knrm.medmarco.tar.gz', text_field='abstract', \n",
    "                                        expected_md5=\"d70b1d4f899690dae51161537e69ed5a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299,
     "referenced_widgets": [
      "02765e4f002142a9835aabf3e5150c8f",
      "a0d64138cb8e44218ce0c18fbaf44cd0",
      "44eee719e6794b4abf741c042d184e76",
      "d1a059bca1f84d5e90f95e4b8fee47e8",
      "a9e05b46cef04c9687dc45889f11a656",
      "576320a691254eed82a9405f63d086f1",
      "59a9941b61b74e4ca7d83ac0cc7a9229",
      "37de10336b424425b8f38240db4e5956",
      "0cc162ed4f424b5190d5e658a29d758a",
      "380f8933c57f4b9486da05b2becfc18d",
      "69938afc305f4151913e9ef85049f5ea"
     ]
    },
    "executionInfo": {
     "elapsed": 13815,
     "status": "ok",
     "timestamp": 1666982378104,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "1BQQKv8lL0Ta",
    "outputId": "1a98f319-6ff2-4a4b-a1cb-73db7d414e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:04:54,954][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 02:04:54,956][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/1250 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:04:58,728][onir_pt][DEBUG] [finished] batches: [3.77s] [1250it] [331.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>P.10</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>mrt</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>P.10 +</th>\n",
       "      <th>P.10 -</th>\n",
       "      <th>P.10 p-value</th>\n",
       "      <th>ndcg +</th>\n",
       "      <th>ndcg -</th>\n",
       "      <th>ndcg p-value</th>\n",
       "      <th>ndcg_cut.10 +</th>\n",
       "      <th>ndcg_cut.10 -</th>\n",
       "      <th>ndcg_cut.10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.068056</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.609058</td>\n",
       "      <td>52.209043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DPH &gt;&gt; KNRM</td>\n",
       "      <td>0.065103</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.160561</td>\n",
       "      <td>0.532655</td>\n",
       "      <td>126.053247</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.095852</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.024604</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.028273</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.005972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name       map   P.10      ndcg  ndcg_cut.10         mrt  map +  \\\n",
       "0          DPH  0.068056  0.658  0.165653     0.609058   52.209043    NaN   \n",
       "1  DPH >> KNRM  0.065103  0.598  0.160561     0.532655  126.053247   20.0   \n",
       "\n",
       "   map -  map p-value  P.10 +  P.10 -  P.10 p-value  ndcg +  ndcg -  \\\n",
       "0    NaN          NaN     NaN     NaN           NaN     NaN     NaN   \n",
       "1   30.0     0.095852    12.0    26.0      0.024604    20.0    30.0   \n",
       "\n",
       "   ndcg p-value  ndcg_cut.10 +  ndcg_cut.10 -  ndcg_cut.10 p-value  \n",
       "0           NaN            NaN            NaN                  NaN  \n",
       "1      0.028273           20.0           30.0             0.005972  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = br >> pt.text.get_text(dataset, 'abstract') >> knrm\n",
    "pt.Experiment(\n",
    "    [br, pipeline2],\n",
    "    topics,\n",
    "    qrels,\n",
    "    names=['DPH', 'DPH >> KNRM'],\n",
    "    baseline=0,\n",
    "    eval_metrics=[\"map\", \"ndcg\", 'ndcg_cut.10', 'P.10', 'mrt']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aI1_8O8rtXKK"
   },
   "source": [
    "The tuned performance is a little better than before, but `knrm` still underperforms our first-stage ranking model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79l1jn0pRQEY"
   },
   "source": [
    "## Reranking with BERT\n",
    "\n",
    "Large language models such as [BERT](https://arxiv.org/abs/1810.04805) are much more powerful neural models that have been shown to be effective for ranking like we discussed in class. \n",
    "\n",
    "Like with `knrm`, we'll start by using BERT for re-ranking with its initial parameters. These parameters have been turned for the masked language modeling (i.e., filling a word in the blank) and predicting the next sentence--but have not been tuned for IR at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49692,
     "status": "ok",
     "timestamp": 1666982590098,
     "user": {
      "displayName": "Yi-An Chu",
      "userId": "13218931171162323923"
     },
     "user_tz": 240
    },
    "id": "-qlXPHqN3iO0",
    "outputId": "ceaf78bc-6311-4e78-fe1e-4f43e053637f"
   },
   "outputs": [],
   "source": [
    "del knrm # clear out memory from KNRM (useful for GPU)\n",
    "vbert = onir_pt.reranker('vanilla_transformer', 'bert', text_field='abstract', vocab_config={'train': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "progrVwaunrn"
   },
   "source": [
    "Let's see how this non-IR trained model does on CORD10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "20789d42cd9247a689816e73eec22eac",
      "a503a4c2db344890b6d9a865642e9ea7",
      "9005f45d8f7742d8ae68b3ecf4afd2e7",
      "67fb386486244f52903806582b64882f",
      "20475c20e3d84772941d0d08ec99674b",
      "485375142e0843c6b45036f1aa397754",
      "52cc333559b34d8f9eba36bc8c754cdd",
      "ad7410f8f8d7429ab9ded6c18107efff",
      "aa4a3a71b642475fa9fb868eb9354b34",
      "4d611a1adc704300b1f2866a12f50f43",
      "8e5777f558d74059af1e4681ff354302"
     ]
    },
    "id": "PkasovrjQjy0",
    "outputId": "63da0a82-69d0-487d-f03d-a767f0633a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:05:09,095][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 02:05:09,100][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/1250 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:33:43,707][onir_pt][DEBUG] [finished] batches: [28:35] [1250it] [ 1.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>P.10</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>mrt</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>P.10 +</th>\n",
       "      <th>P.10 -</th>\n",
       "      <th>P.10 p-value</th>\n",
       "      <th>ndcg +</th>\n",
       "      <th>ndcg -</th>\n",
       "      <th>ndcg p-value</th>\n",
       "      <th>ndcg_cut.10 +</th>\n",
       "      <th>ndcg_cut.10 -</th>\n",
       "      <th>ndcg_cut.10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.068056</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.609058</td>\n",
       "      <td>46.691339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DPH &gt;&gt; VBERT</td>\n",
       "      <td>0.056413</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.147048</td>\n",
       "      <td>0.374197</td>\n",
       "      <td>34342.213411</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.462198e-07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.134415e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name       map   P.10      ndcg  ndcg_cut.10           mrt  map +  \\\n",
       "0           DPH  0.068056  0.658  0.165653     0.609058     46.691339    NaN   \n",
       "1  DPH >> VBERT  0.056413  0.458  0.147048     0.374197  34342.213411    8.0   \n",
       "\n",
       "   map -  map p-value  P.10 +  P.10 -  P.10 p-value  ndcg +  ndcg -  \\\n",
       "0    NaN          NaN     NaN     NaN           NaN     NaN     NaN   \n",
       "1   42.0     0.000006     6.0    37.0  9.462198e-07     5.0    45.0   \n",
       "\n",
       "   ndcg p-value  ndcg_cut.10 +  ndcg_cut.10 -  ndcg_cut.10 p-value  \n",
       "0           NaN            NaN            NaN                  NaN  \n",
       "1      0.000001            8.0           41.0         4.134415e-09  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline3 = br % 100 >> pt.text.get_text(dataset, 'abstract') >> vbert\n",
    "pt.Experiment(\n",
    "    [br, pipeline3],\n",
    "    topics,\n",
    "    qrels,\n",
    "    names=['DPH', 'DPH >> VBERT'],\n",
    "    baseline=0,\n",
    "    eval_metrics=[\"map\", \"ndcg\", 'ndcg_cut.10', 'P.10', 'mrt']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBrfNZ_1u_pD"
   },
   "source": [
    "As we see, although the ERT model is pre-trained for recognizing language, it doesn't do very well at ranking on our benchmark. To get better performance, we'll need to tune for the task of relevance ranking.\n",
    "\n",
    "We can train the model for ranking (as shown above for KNRM) or we can download a trained model. Here, we will use the [SLEDGE](https://arxiv.org/abs/2010.05987) model, which is a BERT model trained on scientific text and tuned on medical queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VsXQKNyYSXOj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:33:43,877][onir_pt][INFO] using cached checkpoint: /home/yianchu/data/onir/model_checkpoints/1153203ea2abbdf7f760fa6956a83d83\n"
     ]
    }
   ],
   "source": [
    "vbert = onir_pt.reranker.from_checkpoint('https://macavaney.us/scibert-medmarco.tar.gz', \n",
    "                                         text_field='abstract', expected_md5=\"854966d0b61543ffffa44cea627ab63b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3rD4FxFZELc"
   },
   "source": [
    "Let's run another experiment to see how this new model trained for IR does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dUH-daNJSoNy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 02:34:10,491][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 02:34:10,495][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/1250 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:00:17,566][onir_pt][DEBUG] [finished] batches: [26:07] [1250it] [ 1.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>P.10</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>mrt</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>P.10 +</th>\n",
       "      <th>P.10 -</th>\n",
       "      <th>P.10 p-value</th>\n",
       "      <th>ndcg +</th>\n",
       "      <th>ndcg -</th>\n",
       "      <th>ndcg p-value</th>\n",
       "      <th>ndcg_cut.10 +</th>\n",
       "      <th>ndcg_cut.10 -</th>\n",
       "      <th>ndcg_cut.10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.068056</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.609058</td>\n",
       "      <td>50.628312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DPH &gt;&gt; Trained-BERT</td>\n",
       "      <td>0.075710</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.173079</td>\n",
       "      <td>0.701995</td>\n",
       "      <td>31391.654690</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.012156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name       map   P.10      ndcg  ndcg_cut.10           mrt  \\\n",
       "0                  DPH  0.068056  0.658  0.165653     0.609058     50.628312   \n",
       "1  DPH >> Trained-BERT  0.075710  0.770  0.173079     0.701995  31391.654690   \n",
       "\n",
       "   map +  map -  map p-value  P.10 +  P.10 -  P.10 p-value  ndcg +  ndcg -  \\\n",
       "0    NaN    NaN          NaN     NaN     NaN           NaN     NaN     NaN   \n",
       "1   36.0   14.0     0.001278    28.0    11.0      0.000851    36.0    14.0   \n",
       "\n",
       "   ndcg p-value  ndcg_cut.10 +  ndcg_cut.10 -  ndcg_cut.10 p-value  \n",
       "0           NaN            NaN            NaN                  NaN  \n",
       "1      0.010118           31.0           19.0             0.012156  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline4 = br % 100 >> pt.text.get_text(dataset, 'abstract') >> vbert\n",
    "pt.Experiment(\n",
    "    [br, pipeline4],\n",
    "    topics,\n",
    "    qrels,\n",
    "    names=['DPH', 'DPH >> Trained-BERT'],\n",
    "    baseline=0,\n",
    "    eval_metrics=[\"map\", \"ndcg\", 'ndcg_cut.10', 'P.10', 'mrt']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtAxDQHyv4ON"
   },
   "source": [
    "Training helped a lot! We're able to improve upon the initial ranking from `BatchRetrieve`. However, from looking at `mrt` we can see that this is pretty slow to run--and this was using a GPU! This performance time underscores the trade-off in using large language models at retrieval time: they may perform better, but could be much slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DngIvFrAZEOo"
   },
   "source": [
    "# Deep learning at indexing time: doc2query\n",
    "\n",
    "Instead of using our large language models to rerank, another option is to use them at _indexing time_ to augment our documents. In class, we discussed one such option, doc2query, that augments an inverted index structure by predicting queries that may be used to search for the document, and appending those to the document text.\n",
    "\n",
    "We can use doc2query using the `pyterrier_doc2query` package, which was loaded at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yx1_Gr3ZEOp"
   },
   "source": [
    "### Loading a pre-trained model\n",
    "\n",
    "We'll start by using a version of the doc2query model released by the authors that is trained on the MS MARCO collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "q3t9GSGZZEOp"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"t5-base.zip\"):\n",
    "    !wget https://git.uwaterloo.ca/jimmylin/doc2query-data/raw/master/T5-passage/t5-base.zip\n",
    "    !unzip t5-base.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjocNKaLZEOr"
   },
   "source": [
    "We can load the model weights by specifying the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "f2SvJ-lwZEOv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yianchu/.local/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# doc2query = pyterrier_doc2query.Doc2Query('model.ckpt-1004000', batch_size=8)\n",
    "doc2query = pyterrier_doc2query.Doc2Query('t5-base', batch_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWTT0dowZEOz"
   },
   "source": [
    "### Running doc2queries on sample text\n",
    "\n",
    "Let's see what queries it predicts for the sample document that we've made up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Y-Uqjj8lZEO2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The University of Michigan School of Information (UMSI) delivers innovative, elegant and ethical solutions connecting people, information and technology. The school was one of the first iSchools in the nation and is the premier institution studying and using technology to improve human computer interactions.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([{\"docno\" : \"d1\", \"text\" :\"The University of Michigan School of Information (UMSI) delivers innovative, elegant and ethical solutions connecting people, information and technology. The school was one of the first iSchools in the nation and is the premier institution studying and using technology to improve human computer interactions.\"}])\n",
    "df.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nk87clb9ZEPA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michigan School of Information is the premier iSchool focusing on and using technology to improve human computer interaction.\\nis an innovative and innovative college of Information (UMSI) is an elite school of information at the University of Michigan. The school is leading the nation in iSchools and human computer interaction.\\nis the leading institution studying and using technology to improve people, information and technology. Michigan School of Information (UMSI) is the premiere institution researching and using technology to improve human computer interaction.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2query_df = doc2query(df)\n",
    "doc2query_df.iloc[0].querygen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbiK3tDDZEPB"
   },
   "source": [
    "Not too bad, though the questions are somewhat generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yo4HaJvWZEPB"
   },
   "source": [
    "### Loading an index of doc2query documents\n",
    "\n",
    "Let's see how doc2query does on improving the performance in the TREC COVID data. Since indexing with doc2query takes a while (due to needing to run the deep learning models), we've provide an index with the text already added.\n",
    "\n",
    "If you would like to index the collection with doc2query yourself (or use doc2query for your course project), you can use the following code:\n",
    "\n",
    "```python\n",
    "dataset = pt.get_dataset(\"irds:cord19/trec-covid\")\n",
    "indexer = (\n",
    "  pyterrier_doc2query.Doc2Query('model.ckpt-1004000', doc_attr='abstract', batch_size=8, append=True) # aply doc2query on abstracts and append\n",
    "  >> pt.apply.generic(lambda df: df.rename(columns={'abstract': 'text'}) # rename \"abstract\" column to \"text\" for indexing\n",
    "  >> pt.IterDictIndexer(\"./doc2query_index_path\")) # index the expanded documents\n",
    "indexref = indexer.index(dataset.get_corpus_iter())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_soov5ZIZEPC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-01 03:00:41--  http://www.dcs.gla.ac.uk/~craigm/ecir2021-tutorial/doc2query_marco_cord19.zip\n",
      "Resolving proxy.arc-ts.umich.edu (proxy.arc-ts.umich.edu)... 141.213.136.200\n",
      "Connecting to proxy.arc-ts.umich.edu (proxy.arc-ts.umich.edu)|141.213.136.200|:3128... connected.\n",
      "Proxy request sent, awaiting response... 302 Found\n",
      "Location: https://www.dcs.gla.ac.uk/~craigm/ecir2021-tutorial/doc2query_marco_cord19.zip [following]\n",
      "--2022-11-01 03:00:41--  https://www.dcs.gla.ac.uk/~craigm/ecir2021-tutorial/doc2query_marco_cord19.zip\n",
      "Connecting to proxy.arc-ts.umich.edu (proxy.arc-ts.umich.edu)|141.213.136.200|:3128... connected.\n",
      "ERROR: The certificate of ‘www.dcs.gla.ac.uk’ is not trusted.\n",
      "ERROR: The certificate of ‘www.dcs.gla.ac.uk’ hasn't got a known issuer.\n",
      "unzip:  cannot find or open doc2query_marco_cord19.zip, doc2query_marco_cord19.zip.zip or doc2query_marco_cord19.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('doc2query_marco_cord19.zip'):\n",
    "  !wget http://www.dcs.gla.ac.uk/~craigm/ecir2021-tutorial/doc2query_marco_cord19.zip\n",
    "  !unzip doc2query_marco_cord19.zip\n",
    "# doc2query_indexref = pt.IndexRef.of('./doc2query_index_path/data.properties')\n",
    "doc2query_indexref = pt.IndexRef.of('./doc2query_index_path/data.properties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH2SnvoiZEPD"
   },
   "source": [
    "Let's look at the results on TREC COVID by first merging the scores with the rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ogNpsDudZEPD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yianchu/.local/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101299</td>\n",
       "      <td>jwmrgy5d</td>\n",
       "      <td>0</td>\n",
       "      <td>8.427298</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>COVID-19 in the heart and the lungs: could we ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>182167</td>\n",
       "      <td>g8grcy5j</td>\n",
       "      <td>0</td>\n",
       "      <td>13.922648</td>\n",
       "      <td>coronavirus response to weather changes</td>\n",
       "      <td>The Stirling Protocol – Putting the environmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>85678</td>\n",
       "      <td>tl30wlpy</td>\n",
       "      <td>0</td>\n",
       "      <td>7.224180</td>\n",
       "      <td>coronavirus immunity</td>\n",
       "      <td>Receptor-dependent coronavirus infection of de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>145871</td>\n",
       "      <td>l5fxswfz</td>\n",
       "      <td>0</td>\n",
       "      <td>12.773362</td>\n",
       "      <td>how do people die from the coronavirus</td>\n",
       "      <td>Analysis on 54 Mortality Cases of Coronavirus ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180990</td>\n",
       "      <td>3sepefqa</td>\n",
       "      <td>0</td>\n",
       "      <td>12.995980</td>\n",
       "      <td>animal models of covid 19</td>\n",
       "      <td>Current global vaccine and drug efforts agains...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid   docid     docno  rank      score  \\\n",
       "0   1  101299  jwmrgy5d     0   8.427298   \n",
       "1   2  182167  g8grcy5j     0  13.922648   \n",
       "2   3   85678  tl30wlpy     0   7.224180   \n",
       "3   4  145871  l5fxswfz     0  12.773362   \n",
       "4   5  180990  3sepefqa     0  12.995980   \n",
       "\n",
       "                                     query  \\\n",
       "0                       coronavirus origin   \n",
       "1  coronavirus response to weather changes   \n",
       "2                     coronavirus immunity   \n",
       "3   how do people die from the coronavirus   \n",
       "4                animal models of covid 19   \n",
       "\n",
       "                                               title  label iteration  \n",
       "0  COVID-19 in the heart and the lungs: could we ...    0.0         5  \n",
       "1  The Stirling Protocol – Putting the environmen...    0.0         4  \n",
       "2  Receptor-dependent coronavirus infection of de...    NaN       NaN  \n",
       "3  Analysis on 54 Mortality Cases of Coronavirus ...    2.0       1.5  \n",
       "4  Current global vaccine and drug efforts agains...    0.0         4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset('irds:cord19/trec-covid')\n",
    "pipeline = pt.BatchRetrieve(doc2query_indexref) % 1 >> pt.text.get_text(dataset, 'title')\n",
    "res = pipeline(dataset.get_topics('title'))\n",
    "res.merge(dataset.get_qrels(), how='left').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPXOTmvZZEPE"
   },
   "source": [
    "What kind of queries does doc2query generate for the CORD19 documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1hm-wp7AZEPF"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525595bee554486badf16998f0bcd446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cord19/trec-covid documents:   0%|          | 0/192509 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l5fxswfz\n",
      "Since the identification of the first case of coronavirus disease 2019 (COVID-19), the global number of confirmed cases as of March 15, 2020, is 156,400, with total deaths in 5,833 (3.7%) worldwide. Here, we summarize the morality data from February 19 when\n",
      "Since the identification of the first case of COVID-19 in 2019, with the global number of confirmed cases as of March 15, 2020, is 156,400, with total death in 5,833 (3,7%). Here we summarize the morality data from February 19 when we identified the first case of CO\n",
      "156,400 worldwide, and total death in 5,833 (3.7%) worldwide. Since the identification of the first case of coronavirus disease 2019 (COVID-19), the global number of confirmed cases as of March 15, 2020, is 156,400, with total death in 5,83\n",
      "Since the identification of the first case of coronavirus disease 2019 (COVID-19), the global number of confirmed cases as of March 15, 2020, is 156,400, with total death in 5,833 (3.7%) worldwide. Here, we summarize the morality data from February 19 when the first mortality occurred to 0 am, March 10, 2020, in Korea with comparison to other countries. The overall case fatality rate of COVID-19 in Korea was 0.7% as of 0 am, March 10, 2020.\n",
      "3sepefqa\n",
      "Currently, COVID-19 has become one of the biggest health concern along with huge economic burden. the COVID-19 a major public health challenge. China are creating new drugs for treating COVID-19 patients. Researchers are also focusing on treating COVID-19 with\n",
      "Since the disease, the cost of COVID-19 has been immense. the condition has become one of the biggest health worry and is becoming the main medical burden among many. In India, COVID-19 is a huge economic burden and big health problem. In the Philippines, COVID-19\n",
      "COVID-19 the disease, huge economic burden. COVID-19 is one of the health concerns of people in China. China are investing heavily in COVID-19 research to treat the disease. China are investing in COVID-19 research and research, along with huge social\n",
      "COVID-19 has become one of the biggest health concern, along with huge economic burden. With no clear remedies to treat the disease, doctors are repurposing drugs like chloroquine and remdesivir to treat COVID-19 patients. In parallel, research institutes in collaboration with biotech companies have identified strategies to use viral proteins as vaccine candidates for COVID-19. Although this looks promising, they still need to pass the test of challenge studies in animal models. As various models for SARS-CoV-2 are under testing phase, biotech companies have bypassed animal studies and moved to Phase I clinical trials. In view of the present outbreak, this looks a justified approach, but the problem is that in the absence of animal studies, we can never predict the outcomes in humans. Since animal models are critical for vaccine development and SARS-CoV-2 has different transmission dynamics, in this review we compare different animal models of SARS-CoV-2 with humans for their pathogenic, immune response and transmission dynamics that make them ideal models for vaccine testing for COVID-19. Another issue of using animal model is the ethics of using animals for research; thus, we also discuss the pros and cons of using animals for vaccine development studies.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(doc for doc in dataset.get_corpus_iter() if doc['docno'] in ('3sepefqa', 'l5fxswfz'))\n",
    "df = df.rename(columns={'abstract': 'text'})\n",
    "doc2query_df = doc2query(df)\n",
    "for querygen, docno, text in zip(doc2query_df['querygen'], doc2query_df['docno'], df['text']):\n",
    "    print(docno)\n",
    "    print(querygen)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xz3LQfObZEPF"
   },
   "source": [
    "## Evaluating the effects of doc2query\n",
    "\n",
    "Here, we'll change our evaluation setup a bit from what we did before. Rather than compare two models for the same index, we'll instead compare the same model (BM25) with two different ways of indexing (two indices)! Our baseline will be an index of CORD19 without the doc2query additions.\n",
    "\n",
    "Let's load a copy of the CORD19 index that we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NJ30R_xtZEPG"
   },
   "outputs": [],
   "source": [
    "indexref = pt.IndexRef.of('./terrier_cord19/data.properties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5XFwNGwZEPH"
   },
   "source": [
    "### Task 2: Write the `Experiment` to compare indices (5 points)\n",
    "Run an `Experiment` using a `BM25` ranker that compares the indices `indexref` and `doc2query_indexref`.  Note that our doc2query model was trained on MS MARCO, which isn't the same kind of collection as CORD19, so this performance tells us how well that model can transfer to a new setting.\n",
    "\n",
    "You should evaluate using the metrics \"map\", \"ndcg\", \"ndcg_cut.10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ogRcnPNWZEPH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indexref</td>\n",
       "      <td>0.195498</td>\n",
       "      <td>0.411103</td>\n",
       "      <td>0.644463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc2query_indexref</td>\n",
       "      <td>0.196293</td>\n",
       "      <td>0.412673</td>\n",
       "      <td>0.623652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name       map      ndcg  ndcg_cut.10\n",
       "0            indexref  0.195498  0.411103     0.644463\n",
       "1  doc2query_indexref  0.196293  0.412673     0.623652"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "  [pt.BatchRetrieve(indexref, wmodel=\"BM25\"), pt.BatchRetrieve(doc2query_indexref, wmodel=\"BM25\")],\n",
    "  topics,\n",
    "  qrels,\n",
    "  eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut.10\"],\n",
    "  names=[\"indexref\", \"doc2query_indexref\"]\n",
    ")\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKtBlGvdZEPH"
   },
   "source": [
    "# Task 3: Train a new model! (30 points)\n",
    "\n",
    "All of the prior exercises have had you working with either off-the-shelf models (not trained for IR) or models that someone else has trained for you. To give you a sense of how to train a model, your primary task in this notebook is to train a simple `knrm` model, which should be relatively efficient to train on a GPU. \n",
    "\n",
    "To keep thinsg simple, we'll use the same setup for CORD19 that we did in Part 2 (30 queries in train, 5 in dev, 15 queries in test) which is still relatively small for training a deep learning model but will get you started on the process. \n",
    "\n",
    "Your tasks are the following:\n",
    "- Load the CORD19 dataset and split it into train, dev, and test. Your test set should have 15 queries, dev set 5 queries, and the rest in train. use a seed of 42 for the `random_state` to ensure consistent results with what we expected.\n",
    "- Create a new `knrm` ranker and a pipeline that uses it\n",
    "- Run an `Experiment` comparing four models:\n",
    "  - a default `BatchRetrieve`, filtering to the top 100 results\n",
    "  - BM25, filtering to the top 100 results\n",
    "  - a pipeline that feeds the top 100 results of the default `BatchRetrieve` to your `knrm` model\n",
    "  - a pipeline that feeds the top 100 results of BM25 to your `knrm` model\n",
    "  \n",
    "Your `Experiment` should evaluate with metrics `\"map\", \"ndcg\", 'ndcg_cut.10', 'P.10', 'mrt'`\n",
    "  \n",
    "We expect to see the `Experiment`'s results in the final cell. You are, of course, welcome to try training any of the fancier models to see how they do as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "MuykcSYFZEPI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yianchu/.local/lib/python3.9/site-packages/pyterrier/datasets.py:435: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df.drop(df.columns.difference(['qid','query']), 1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:00,164][WordvecHashVocab][DEBUG] [starting] reading cached at /home/yianchu/data/onir/vocab/wordvec_hash/fasttext-wiki-news-300d-1M.p\n",
      "[2022-11-01 03:01:01,502][WordvecHashVocab][DEBUG] [finished] reading cached at /home/yianchu/data/onir/vocab/wordvec_hash/fasttext-wiki-news-300d-1M.p [1.34s]\n",
      "[2022-11-01 03:01:07,982][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:01:07,984][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:07,986][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:08,384][onir_pt][DEBUG] [finished] batches: [397ms] [125it] [314.68it/s]\n",
      "[2022-11-01 03:01:08,494][onir_pt][DEBUG] [finished] validation [512ms]\n",
      "[2022-11-01 03:01:08,496][onir_pt][INFO] pre-validation: 0.0073\n",
      "[2022-11-01 03:01:08,533][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:08,537][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:01:08,541][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:14,384][onir_pt][DEBUG] [finished] train pairs: [5.84s] [1024it] [175.39it/s]\n",
      "[2022-11-01 03:01:14,392][onir_pt][DEBUG] [finished] training [5.85s]\n",
      "[2022-11-01 03:01:14,396][onir_pt][INFO] training   it=0 loss=0.2673\n",
      "[2022-11-01 03:01:14,400][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:01:14,404][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:14,408][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:14,841][onir_pt][DEBUG] [finished] batches: [431ms] [125it] [290.35it/s]\n",
      "[2022-11-01 03:01:14,948][onir_pt][DEBUG] [finished] validation [548ms]\n",
      "[2022-11-01 03:01:14,953][onir_pt][INFO] validation it=0 map=0.0068 ndcg=0.0184 P_10=0.0400\n",
      "[2022-11-01 03:01:14,957][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:14,961][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:01:14,965][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:20,427][onir_pt][DEBUG] [finished] train pairs: [5.46s] [1024it] [187.62it/s]\n",
      "[2022-11-01 03:01:20,430][onir_pt][DEBUG] [finished] training [5.47s]\n",
      "[2022-11-01 03:01:20,432][onir_pt][INFO] training   it=1 loss=0.2529\n",
      "[2022-11-01 03:01:20,433][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:01:20,435][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:20,436][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [16ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:20,867][onir_pt][DEBUG] [finished] batches: [429ms] [125it] [291.16it/s]\n",
      "[2022-11-01 03:01:20,973][onir_pt][DEBUG] [finished] validation [539ms]\n",
      "[2022-11-01 03:01:20,975][onir_pt][INFO] validation it=1 map=0.0068 ndcg=0.0182 P_10=0.0380\n",
      "[2022-11-01 03:01:20,976][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:20,978][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:01:20,979][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [16ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:26,011][onir_pt][DEBUG] [finished] train pairs: [5.03s] [1024it] [203.58it/s]\n",
      "[2022-11-01 03:01:26,014][onir_pt][DEBUG] [finished] training [5.04s]\n",
      "[2022-11-01 03:01:26,015][onir_pt][INFO] training   it=2 loss=0.2474\n",
      "[2022-11-01 03:01:26,016][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:01:26,018][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:26,019][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [16ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:26,456][onir_pt][DEBUG] [finished] batches: [435ms] [125it] [287.21it/s]\n",
      "[2022-11-01 03:01:26,560][onir_pt][DEBUG] [finished] validation [543ms]\n",
      "[2022-11-01 03:01:26,562][onir_pt][INFO] validation it=2 map=0.0068 ndcg=0.0184 P_10=0.0360\n",
      "[2022-11-01 03:01:26,563][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:26,565][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:01:26,566][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [16ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:32,650][onir_pt][DEBUG] [finished] train pairs: [6.08s] [1024it] [168.36it/s]\n",
      "[2022-11-01 03:01:32,658][onir_pt][DEBUG] [finished] training [6.09s]\n",
      "[2022-11-01 03:01:32,662][onir_pt][INFO] training   it=3 loss=0.2492\n",
      "[2022-11-01 03:01:32,666][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:01:32,670][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:32,674][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:33,204][onir_pt][DEBUG] [finished] batches: [528ms] [125it] [236.85it/s]\n",
      "[2022-11-01 03:01:33,312][onir_pt][DEBUG] [finished] validation [646ms]\n",
      "[2022-11-01 03:01:33,317][onir_pt][INFO] validation it=3 map=0.0071 ndcg=0.0188 P_10=0.0440\n",
      "[2022-11-01 03:01:33,321][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:33,326][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:01:33,330][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:39,623][onir_pt][DEBUG] [finished] train pairs: [6.29s] [1024it] [162.81it/s]\n",
      "[2022-11-01 03:01:39,631][onir_pt][DEBUG] [finished] training [6.31s]\n",
      "[2022-11-01 03:01:39,635][onir_pt][INFO] training   it=4 loss=0.2603\n",
      "[2022-11-01 03:01:39,639][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:01:39,643][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:39,647][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:40,164][onir_pt][DEBUG] [finished] batches: [515ms] [125it] [242.84it/s]\n",
      "[2022-11-01 03:01:40,270][onir_pt][DEBUG] [finished] validation [631ms]\n",
      "[2022-11-01 03:01:40,275][onir_pt][INFO] validation it=4 map=0.0068 ndcg=0.0184 P_10=0.0380\n",
      "[2022-11-01 03:01:40,279][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:40,284][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:01:40,288][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:46,565][onir_pt][DEBUG] [finished] train pairs: [6.27s] [1024it] [163.23it/s]\n",
      "[2022-11-01 03:01:46,573][onir_pt][DEBUG] [finished] training [6.29s]\n",
      "[2022-11-01 03:01:46,577][onir_pt][INFO] training   it=5 loss=0.2567\n",
      "[2022-11-01 03:01:46,581][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:01:46,585][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:46,589][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:47,105][onir_pt][DEBUG] [finished] batches: [513ms] [125it] [243.58it/s]\n",
      "[2022-11-01 03:01:47,212][onir_pt][DEBUG] [finished] validation [631ms]\n",
      "[2022-11-01 03:01:47,217][onir_pt][INFO] validation it=5 map=0.0068 ndcg=0.0184 P_10=0.0360\n",
      "[2022-11-01 03:01:47,221][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:47,225][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:01:47,229][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:53,446][onir_pt][DEBUG] [finished] train pairs: [6.21s] [1024it] [164.81it/s]\n",
      "[2022-11-01 03:01:53,454][onir_pt][DEBUG] [finished] training [6.23s]\n",
      "[2022-11-01 03:01:53,458][onir_pt][INFO] training   it=6 loss=0.2590\n",
      "[2022-11-01 03:01:53,462][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:01:53,466][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:53,470][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:01:53,980][onir_pt][DEBUG] [finished] batches: [507ms] [125it] [246.51it/s]\n",
      "[2022-11-01 03:01:54,088][onir_pt][DEBUG] [finished] validation [625ms]\n",
      "[2022-11-01 03:01:54,093][onir_pt][INFO] validation it=6 map=0.0083 ndcg=0.0194 P_10=0.0620 <--\n",
      "[2022-11-01 03:01:54,097][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:01:54,102][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:01:54,106][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:00,223][onir_pt][DEBUG] [finished] train pairs: [6.11s] [1024it] [167.51it/s]\n",
      "[2022-11-01 03:02:00,231][onir_pt][DEBUG] [finished] training [6.13s]\n",
      "[2022-11-01 03:02:00,235][onir_pt][INFO] training   it=7 loss=0.2464\n",
      "[2022-11-01 03:02:00,239][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:00,243][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:00,247][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [28ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:00,748][onir_pt][DEBUG] [finished] batches: [499ms] [125it] [250.54it/s]\n",
      "[2022-11-01 03:02:00,854][onir_pt][DEBUG] [finished] validation [615ms]\n",
      "[2022-11-01 03:02:00,859][onir_pt][INFO] validation it=7 map=0.0068 ndcg=0.0183 P_10=0.0380\n",
      "[2022-11-01 03:02:00,863][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:00,867][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:00,872][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:06,951][onir_pt][DEBUG] [finished] train pairs: [6.08s] [1024it] [168.56it/s]\n",
      "[2022-11-01 03:02:06,959][onir_pt][DEBUG] [finished] training [6.09s]\n",
      "[2022-11-01 03:02:06,963][onir_pt][INFO] training   it=8 loss=0.2466\n",
      "[2022-11-01 03:02:06,967][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:06,970][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:06,975][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:07,474][onir_pt][DEBUG] [finished] batches: [497ms] [125it] [251.57it/s]\n",
      "[2022-11-01 03:02:07,582][onir_pt][DEBUG] [finished] validation [616ms]\n",
      "[2022-11-01 03:02:07,587][onir_pt][INFO] validation it=8 map=0.0068 ndcg=0.0183 P_10=0.0380\n",
      "[2022-11-01 03:02:07,591][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:07,595][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:07,599][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [28ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:13,682][onir_pt][DEBUG] [finished] train pairs: [6.08s] [1024it] [168.46it/s]\n",
      "[2022-11-01 03:02:13,690][onir_pt][DEBUG] [finished] training [6.09s]\n",
      "[2022-11-01 03:02:13,694][onir_pt][INFO] training   it=9 loss=0.2454\n",
      "[2022-11-01 03:02:13,698][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:13,702][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:13,706][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:14,205][onir_pt][DEBUG] [finished] batches: [496ms] [125it] [251.96it/s]\n",
      "[2022-11-01 03:02:14,311][onir_pt][DEBUG] [finished] validation [613ms]\n",
      "[2022-11-01 03:02:14,316][onir_pt][INFO] validation it=9 map=0.0068 ndcg=0.0182 P_10=0.0360\n",
      "[2022-11-01 03:02:14,320][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:14,324][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:14,328][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:20,410][onir_pt][DEBUG] [finished] train pairs: [6.08s] [1024it] [168.49it/s]\n",
      "[2022-11-01 03:02:20,418][onir_pt][DEBUG] [finished] training [6.09s]\n",
      "[2022-11-01 03:02:20,422][onir_pt][INFO] training   it=10 loss=0.2518\n",
      "[2022-11-01 03:02:20,426][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:20,430][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:20,434][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:20,930][onir_pt][DEBUG] [finished] batches: [494ms] [125it] [252.94it/s]\n",
      "[2022-11-01 03:02:21,038][onir_pt][DEBUG] [finished] validation [613ms]\n",
      "[2022-11-01 03:02:21,043][onir_pt][INFO] validation it=10 map=0.0068 ndcg=0.0182 P_10=0.0380\n",
      "[2022-11-01 03:02:21,047][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:21,051][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:21,055][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:27,193][onir_pt][DEBUG] [finished] train pairs: [6.13s] [1024it] [166.94it/s]\n",
      "[2022-11-01 03:02:27,201][onir_pt][DEBUG] [finished] training [6.15s]\n",
      "[2022-11-01 03:02:27,205][onir_pt][INFO] training   it=11 loss=0.2537\n",
      "[2022-11-01 03:02:27,209][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:27,213][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:27,217][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:27,741][onir_pt][DEBUG] [finished] batches: [521ms] [125it] [240.06it/s]\n",
      "[2022-11-01 03:02:27,847][onir_pt][DEBUG] [finished] validation [638ms]\n",
      "[2022-11-01 03:02:27,852][onir_pt][INFO] validation it=11 map=0.0075 ndcg=0.0190 P_10=0.0520\n",
      "[2022-11-01 03:02:27,856][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:27,861][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:27,865][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:34,149][onir_pt][DEBUG] [finished] train pairs: [6.28s] [1024it] [163.05it/s]\n",
      "[2022-11-01 03:02:34,157][onir_pt][DEBUG] [finished] training [6.30s]\n",
      "[2022-11-01 03:02:34,161][onir_pt][INFO] training   it=12 loss=0.2507\n",
      "[2022-11-01 03:02:34,165][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:34,169][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:34,173][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:34,698][onir_pt][DEBUG] [finished] batches: [522ms] [125it] [239.35it/s]\n",
      "[2022-11-01 03:02:34,807][onir_pt][DEBUG] [finished] validation [642ms]\n",
      "[2022-11-01 03:02:34,812][onir_pt][INFO] validation it=12 map=0.0081 ndcg=0.0195 P_10=0.0600\n",
      "[2022-11-01 03:02:34,816][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:34,820][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:34,824][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:41,038][onir_pt][DEBUG] [finished] train pairs: [6.21s] [1024it] [164.90it/s]\n",
      "[2022-11-01 03:02:41,048][onir_pt][DEBUG] [finished] training [6.23s]\n",
      "[2022-11-01 03:02:41,052][onir_pt][INFO] training   it=13 loss=0.2400\n",
      "[2022-11-01 03:02:41,057][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:41,062][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:41,064][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [33ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:41,599][onir_pt][DEBUG] [finished] batches: [531ms] [125it] [235.53it/s]\n",
      "[2022-11-01 03:02:41,704][onir_pt][DEBUG] [finished] validation [647ms]\n",
      "[2022-11-01 03:02:41,709][onir_pt][INFO] validation it=13 map=0.0081 ndcg=0.0195 P_10=0.0600\n",
      "[2022-11-01 03:02:41,713][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:41,717][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:41,721][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:47,927][onir_pt][DEBUG] [finished] train pairs: [6.20s] [1024it] [165.13it/s]\n",
      "[2022-11-01 03:02:47,934][onir_pt][DEBUG] [finished] training [6.22s]\n",
      "[2022-11-01 03:02:47,939][onir_pt][INFO] training   it=14 loss=0.2372\n",
      "[2022-11-01 03:02:47,942][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:47,946][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:47,951][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:48,482][onir_pt][DEBUG] [finished] batches: [529ms] [125it] [236.11it/s]\n",
      "[2022-11-01 03:02:48,589][onir_pt][DEBUG] [finished] validation [647ms]\n",
      "[2022-11-01 03:02:48,594][onir_pt][INFO] validation it=14 map=0.0081 ndcg=0.0198 P_10=0.0620\n",
      "[2022-11-01 03:02:48,599][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:48,603][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:48,607][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:54,858][onir_pt][DEBUG] [finished] train pairs: [6.25s] [1024it] [163.92it/s]\n",
      "[2022-11-01 03:02:54,866][onir_pt][DEBUG] [finished] training [6.26s]\n",
      "[2022-11-01 03:02:54,870][onir_pt][INFO] training   it=15 loss=0.2327\n",
      "[2022-11-01 03:02:54,874][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:02:54,878][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:54,882][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:02:55,412][onir_pt][DEBUG] [finished] batches: [527ms] [125it] [236.97it/s]\n",
      "[2022-11-01 03:02:55,517][onir_pt][DEBUG] [finished] validation [643ms]\n",
      "[2022-11-01 03:02:55,522][onir_pt][INFO] validation it=15 map=0.0080 ndcg=0.0194 P_10=0.0560\n",
      "[2022-11-01 03:02:55,526][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:02:55,530][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:02:55,534][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:01,826][onir_pt][DEBUG] [finished] train pairs: [6.29s] [1024it] [162.85it/s]\n",
      "[2022-11-01 03:03:01,834][onir_pt][DEBUG] [finished] training [6.30s]\n",
      "[2022-11-01 03:03:01,838][onir_pt][INFO] training   it=16 loss=0.2448\n",
      "[2022-11-01 03:03:01,842][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:01,846][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:01,850][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:02,404][onir_pt][DEBUG] [finished] batches: [551ms] [125it] [226.72it/s]\n",
      "[2022-11-01 03:03:02,512][onir_pt][DEBUG] [finished] validation [670ms]\n",
      "[2022-11-01 03:03:02,517][onir_pt][INFO] validation it=16 map=0.0080 ndcg=0.0193 P_10=0.0540\n",
      "[2022-11-01 03:03:02,521][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:02,525][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:02,529][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:08,950][onir_pt][DEBUG] [finished] train pairs: [6.42s] [1024it] [159.59it/s]\n",
      "[2022-11-01 03:03:08,958][onir_pt][DEBUG] [finished] training [6.43s]\n",
      "[2022-11-01 03:03:08,962][onir_pt][INFO] training   it=17 loss=0.2257\n",
      "[2022-11-01 03:03:08,966][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:08,970][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:08,974][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:09,540][onir_pt][DEBUG] [finished] batches: [564ms] [125it] [221.73it/s]\n",
      "[2022-11-01 03:03:09,648][onir_pt][DEBUG] [finished] validation [681ms]\n",
      "[2022-11-01 03:03:09,652][onir_pt][INFO] validation it=17 map=0.0078 ndcg=0.0191 P_10=0.0480\n",
      "[2022-11-01 03:03:09,656][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:09,661][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:09,665][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:16,068][onir_pt][DEBUG] [finished] train pairs: [6.40s] [1024it] [160.02it/s]\n",
      "[2022-11-01 03:03:16,077][onir_pt][DEBUG] [finished] training [6.42s]\n",
      "[2022-11-01 03:03:16,082][onir_pt][INFO] training   it=18 loss=0.2368\n",
      "[2022-11-01 03:03:16,087][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:16,091][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:16,094][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [32ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:16,650][onir_pt][DEBUG] [finished] batches: [551ms] [125it] [226.88it/s]\n",
      "[2022-11-01 03:03:16,755][onir_pt][DEBUG] [finished] validation [669ms]\n",
      "[2022-11-01 03:03:16,760][onir_pt][INFO] validation it=18 map=0.0075 ndcg=0.0190 P_10=0.0520\n",
      "[2022-11-01 03:03:16,764][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:16,768][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:16,772][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:23,188][onir_pt][DEBUG] [finished] train pairs: [6.41s] [1024it] [159.70it/s]\n",
      "[2022-11-01 03:03:23,196][onir_pt][DEBUG] [finished] training [6.43s]\n",
      "[2022-11-01 03:03:23,200][onir_pt][INFO] training   it=19 loss=0.2471\n",
      "[2022-11-01 03:03:23,204][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:23,208][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:23,212][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:23,766][onir_pt][DEBUG] [finished] batches: [551ms] [125it] [226.97it/s]\n",
      "[2022-11-01 03:03:23,871][onir_pt][DEBUG] [finished] validation [667ms]\n",
      "[2022-11-01 03:03:23,876][onir_pt][INFO] validation it=19 map=0.0075 ndcg=0.0190 P_10=0.0520\n",
      "[2022-11-01 03:03:23,880][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:23,884][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:23,888][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:30,165][onir_pt][DEBUG] [finished] train pairs: [6.27s] [1024it] [163.24it/s]\n",
      "[2022-11-01 03:03:30,173][onir_pt][DEBUG] [finished] training [6.29s]\n",
      "[2022-11-01 03:03:30,177][onir_pt][INFO] training   it=20 loss=0.2451\n",
      "[2022-11-01 03:03:30,181][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:30,185][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:30,189][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:30,747][onir_pt][DEBUG] [finished] batches: [555ms] [125it] [225.38it/s]\n",
      "[2022-11-01 03:03:30,855][onir_pt][DEBUG] [finished] validation [673ms]\n",
      "[2022-11-01 03:03:30,860][onir_pt][INFO] validation it=20 map=0.0072 ndcg=0.0187 P_10=0.0400\n",
      "[2022-11-01 03:03:30,864][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:30,868][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:30,872][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:37,152][onir_pt][DEBUG] [finished] train pairs: [6.28s] [1024it] [163.15it/s]\n",
      "[2022-11-01 03:03:37,160][onir_pt][DEBUG] [finished] training [6.29s]\n",
      "[2022-11-01 03:03:37,164][onir_pt][INFO] training   it=21 loss=0.2550\n",
      "[2022-11-01 03:03:37,168][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:37,172][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:37,176][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:37,729][onir_pt][DEBUG] [finished] batches: [549ms] [125it] [227.62it/s]\n",
      "[2022-11-01 03:03:37,835][onir_pt][DEBUG] [finished] validation [667ms]\n",
      "[2022-11-01 03:03:37,840][onir_pt][INFO] validation it=21 map=0.0068 ndcg=0.0183 P_10=0.0380\n",
      "[2022-11-01 03:03:37,844][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:37,848][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:37,852][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:44,060][onir_pt][DEBUG] [finished] train pairs: [6.20s] [1024it] [165.07it/s]\n",
      "[2022-11-01 03:03:44,068][onir_pt][DEBUG] [finished] training [6.22s]\n",
      "[2022-11-01 03:03:44,072][onir_pt][INFO] training   it=22 loss=0.2500\n",
      "[2022-11-01 03:03:44,076][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:44,080][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:44,084][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:44,642][onir_pt][DEBUG] [finished] batches: [555ms] [125it] [225.06it/s]\n",
      "[2022-11-01 03:03:44,748][onir_pt][DEBUG] [finished] validation [672ms]\n",
      "[2022-11-01 03:03:44,753][onir_pt][INFO] validation it=22 map=0.0068 ndcg=0.0183 P_10=0.0380\n",
      "[2022-11-01 03:03:44,757][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:44,761][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:44,765][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:51,037][onir_pt][DEBUG] [finished] train pairs: [6.27s] [1024it] [163.38it/s]\n",
      "[2022-11-01 03:03:51,045][onir_pt][DEBUG] [finished] training [6.28s]\n",
      "[2022-11-01 03:03:51,049][onir_pt][INFO] training   it=23 loss=0.2580\n",
      "[2022-11-01 03:03:51,053][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:51,057][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:51,061][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:51,616][onir_pt][DEBUG] [finished] batches: [553ms] [125it] [226.08it/s]\n",
      "[2022-11-01 03:03:51,724][onir_pt][DEBUG] [finished] validation [671ms]\n",
      "[2022-11-01 03:03:51,729][onir_pt][INFO] validation it=23 map=0.0068 ndcg=0.0183 P_10=0.0380\n",
      "[2022-11-01 03:03:51,733][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:51,737][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:51,741][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:58,047][onir_pt][DEBUG] [finished] train pairs: [6.30s] [1024it] [162.49it/s]\n",
      "[2022-11-01 03:03:58,055][onir_pt][DEBUG] [finished] training [6.32s]\n",
      "[2022-11-01 03:03:58,059][onir_pt][INFO] training   it=24 loss=0.2658\n",
      "[2022-11-01 03:03:58,063][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:03:58,067][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:58,071][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:03:58,633][onir_pt][DEBUG] [finished] batches: [560ms] [125it] [223.36it/s]\n",
      "[2022-11-01 03:03:58,741][onir_pt][DEBUG] [finished] validation [678ms]\n",
      "[2022-11-01 03:03:58,746][onir_pt][INFO] validation it=24 map=0.0068 ndcg=0.0184 P_10=0.0380\n",
      "[2022-11-01 03:03:58,750][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:03:58,755][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:03:58,759][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:05,051][onir_pt][DEBUG] [finished] train pairs: [6.29s] [1024it] [162.85it/s]\n",
      "[2022-11-01 03:04:05,058][onir_pt][DEBUG] [finished] training [6.30s]\n",
      "[2022-11-01 03:04:05,062][onir_pt][INFO] training   it=25 loss=0.2653\n",
      "[2022-11-01 03:04:05,066][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:05,070][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:05,075][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:05,630][onir_pt][DEBUG] [finished] batches: [553ms] [125it] [225.85it/s]\n",
      "[2022-11-01 03:04:05,739][onir_pt][DEBUG] [finished] validation [672ms]\n",
      "[2022-11-01 03:04:05,744][onir_pt][INFO] validation it=25 map=0.0068 ndcg=0.0183 P_10=0.0380\n",
      "[2022-11-01 03:04:05,748][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:05,752][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:04:05,756][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:12,019][onir_pt][DEBUG] [finished] train pairs: [6.26s] [1024it] [163.61it/s]\n",
      "[2022-11-01 03:04:12,027][onir_pt][DEBUG] [finished] training [6.27s]\n",
      "[2022-11-01 03:04:12,031][onir_pt][INFO] training   it=26 loss=0.2472\n",
      "[2022-11-01 03:04:12,035][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:12,038][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:12,043][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:12,606][onir_pt][DEBUG] [finished] batches: [560ms] [125it] [223.02it/s]\n",
      "[2022-11-01 03:04:12,713][onir_pt][DEBUG] [finished] validation [679ms]\n",
      "[2022-11-01 03:04:12,718][onir_pt][INFO] validation it=26 map=0.0068 ndcg=0.0183 P_10=0.0380\n",
      "[2022-11-01 03:04:12,722][onir_pt][INFO] early stopping; model reverting back to it=6\n",
      "[2022-11-01 03:04:14,858][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:14,859][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:14,864][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:15,323][onir_pt][DEBUG] [finished] batches: [458ms] [125it] [273.09it/s]\n",
      "[2022-11-01 03:04:15,429][onir_pt][DEBUG] [finished] validation [571ms]\n",
      "[2022-11-01 03:04:15,431][onir_pt][INFO] pre-validation: 0.0104\n",
      "[2022-11-01 03:04:15,433][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:15,435][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:04:15,436][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [16ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:20,458][onir_pt][DEBUG] [finished] train pairs: [5.02s] [1024it] [203.98it/s]\n",
      "[2022-11-01 03:04:20,461][onir_pt][DEBUG] [finished] training [5.03s]\n",
      "[2022-11-01 03:04:20,462][onir_pt][INFO] training   it=0 loss=0.2242\n",
      "[2022-11-01 03:04:20,464][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:20,465][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:20,467][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [16ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:20,937][onir_pt][DEBUG] [finished] batches: [468ms] [125it] [267.12it/s]\n",
      "[2022-11-01 03:04:21,043][onir_pt][DEBUG] [finished] validation [579ms]\n",
      "[2022-11-01 03:04:21,057][onir_pt][INFO] validation it=0 map=0.0105 ndcg=0.0224 P_10=0.0740 <--\n",
      "[2022-11-01 03:04:21,061][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:21,065][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:04:21,069][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:27,209][onir_pt][DEBUG] [finished] train pairs: [6.14s] [1024it] [166.90it/s]\n",
      "[2022-11-01 03:04:27,217][onir_pt][DEBUG] [finished] training [6.15s]\n",
      "[2022-11-01 03:04:27,221][onir_pt][INFO] training   it=1 loss=0.2063\n",
      "[2022-11-01 03:04:27,225][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:27,229][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:27,233][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:27,767][onir_pt][DEBUG] [finished] batches: [531ms] [125it] [235.55it/s]\n",
      "[2022-11-01 03:04:27,878][onir_pt][DEBUG] [finished] validation [653ms]\n",
      "[2022-11-01 03:04:27,883][onir_pt][INFO] validation it=1 map=0.0103 ndcg=0.0224 P_10=0.0620\n",
      "[2022-11-01 03:04:27,887][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:27,891][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:04:27,895][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:34,010][onir_pt][DEBUG] [finished] train pairs: [6.11s] [1024it] [167.59it/s]\n",
      "[2022-11-01 03:04:34,018][onir_pt][DEBUG] [finished] training [6.13s]\n",
      "[2022-11-01 03:04:34,022][onir_pt][INFO] training   it=2 loss=0.2025\n",
      "[2022-11-01 03:04:34,026][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:34,030][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:34,034][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:34,535][onir_pt][DEBUG] [finished] batches: [498ms] [125it] [250.83it/s]\n",
      "[2022-11-01 03:04:34,642][onir_pt][DEBUG] [finished] validation [616ms]\n",
      "[2022-11-01 03:04:34,647][onir_pt][INFO] validation it=2 map=0.0102 ndcg=0.0222 P_10=0.0640\n",
      "[2022-11-01 03:04:34,651][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:34,655][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:04:34,659][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:40,647][onir_pt][DEBUG] [finished] train pairs: [5.98s] [1024it] [171.14it/s]\n",
      "[2022-11-01 03:04:40,655][onir_pt][DEBUG] [finished] training [6.00s]\n",
      "[2022-11-01 03:04:40,659][onir_pt][INFO] training   it=3 loss=0.2045\n",
      "[2022-11-01 03:04:40,662][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:40,666][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:40,670][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:41,156][onir_pt][DEBUG] [finished] batches: [482ms] [125it] [259.17it/s]\n",
      "[2022-11-01 03:04:41,263][onir_pt][DEBUG] [finished] validation [601ms]\n",
      "[2022-11-01 03:04:41,268][onir_pt][INFO] validation it=3 map=0.0102 ndcg=0.0223 P_10=0.0600\n",
      "[2022-11-01 03:04:41,272][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:41,276][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:04:41,280][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:47,183][onir_pt][DEBUG] [finished] train pairs: [5.90s] [1024it] [173.58it/s]\n",
      "[2022-11-01 03:04:47,191][onir_pt][DEBUG] [finished] training [5.92s]\n",
      "[2022-11-01 03:04:47,195][onir_pt][INFO] training   it=4 loss=0.1971\n",
      "[2022-11-01 03:04:47,199][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:47,203][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:47,207][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:47,678][onir_pt][DEBUG] [finished] batches: [468ms] [125it] [267.03it/s]\n",
      "[2022-11-01 03:04:47,786][onir_pt][DEBUG] [finished] validation [586ms]\n",
      "[2022-11-01 03:04:47,791][onir_pt][INFO] validation it=4 map=0.0106 ndcg=0.0230 P_10=0.0760 <--\n",
      "[2022-11-01 03:04:47,796][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:47,800][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:04:47,804][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:53,643][onir_pt][DEBUG] [finished] train pairs: [5.84s] [1024it] [175.49it/s]\n",
      "[2022-11-01 03:04:53,651][onir_pt][DEBUG] [finished] training [5.85s]\n",
      "[2022-11-01 03:04:53,655][onir_pt][INFO] training   it=5 loss=0.1972\n",
      "[2022-11-01 03:04:53,659][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:04:53,663][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:53,667][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:04:54,137][onir_pt][DEBUG] [finished] batches: [467ms] [125it] [267.68it/s]\n",
      "[2022-11-01 03:04:54,243][onir_pt][DEBUG] [finished] validation [584ms]\n",
      "[2022-11-01 03:04:54,248][onir_pt][INFO] validation it=5 map=0.0104 ndcg=0.0227 P_10=0.0680\n",
      "[2022-11-01 03:04:54,252][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:04:54,256][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:04:54,260][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:00,154][onir_pt][DEBUG] [finished] train pairs: [5.89s] [1024it] [173.85it/s]\n",
      "[2022-11-01 03:05:00,162][onir_pt][DEBUG] [finished] training [5.91s]\n",
      "[2022-11-01 03:05:00,166][onir_pt][INFO] training   it=6 loss=0.1800\n",
      "[2022-11-01 03:05:00,170][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:00,174][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:00,178][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:00,645][onir_pt][DEBUG] [finished] batches: [464ms] [125it] [269.44it/s]\n",
      "[2022-11-01 03:05:00,750][onir_pt][DEBUG] [finished] validation [580ms]\n",
      "[2022-11-01 03:05:00,755][onir_pt][INFO] validation it=6 map=0.0105 ndcg=0.0228 P_10=0.0720\n",
      "[2022-11-01 03:05:00,759][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:00,763][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:00,767][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:06,509][onir_pt][DEBUG] [finished] train pairs: [5.74s] [1024it] [178.46it/s]\n",
      "[2022-11-01 03:05:06,517][onir_pt][DEBUG] [finished] training [5.75s]\n",
      "[2022-11-01 03:05:06,521][onir_pt][INFO] training   it=7 loss=0.1841\n",
      "[2022-11-01 03:05:06,525][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:06,529][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:06,533][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:06,996][onir_pt][DEBUG] [finished] batches: [460ms] [125it] [271.87it/s]\n",
      "[2022-11-01 03:05:07,102][onir_pt][DEBUG] [finished] validation [577ms]\n",
      "[2022-11-01 03:05:07,107][onir_pt][INFO] validation it=7 map=0.0105 ndcg=0.0228 P_10=0.0780\n",
      "[2022-11-01 03:05:07,111][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:07,115][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:07,119][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:12,931][onir_pt][DEBUG] [finished] train pairs: [5.81s] [1024it] [176.31it/s]\n",
      "[2022-11-01 03:05:12,939][onir_pt][DEBUG] [finished] training [5.82s]\n",
      "[2022-11-01 03:05:12,943][onir_pt][INFO] training   it=8 loss=0.1843\n",
      "[2022-11-01 03:05:12,946][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:12,949][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:12,950][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [25ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:13,410][onir_pt][DEBUG] [finished] batches: [458ms] [125it] [272.65it/s]\n",
      "[2022-11-01 03:05:13,520][onir_pt][DEBUG] [finished] validation [574ms]\n",
      "[2022-11-01 03:05:13,525][onir_pt][INFO] validation it=8 map=0.0104 ndcg=0.0227 P_10=0.0680\n",
      "[2022-11-01 03:05:13,529][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:13,534][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:13,538][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:19,243][onir_pt][DEBUG] [finished] train pairs: [5.70s] [1024it] [179.60it/s]\n",
      "[2022-11-01 03:05:19,246][onir_pt][DEBUG] [finished] training [5.71s]\n",
      "[2022-11-01 03:05:19,248][onir_pt][INFO] training   it=9 loss=0.1849\n",
      "[2022-11-01 03:05:19,249][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:19,250][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:19,252][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [16ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:19,691][onir_pt][DEBUG] [finished] batches: [438ms] [125it] [285.55it/s]\n",
      "[2022-11-01 03:05:19,795][onir_pt][DEBUG] [finished] validation [546ms]\n",
      "[2022-11-01 03:05:19,797][onir_pt][INFO] validation it=9 map=0.0106 ndcg=0.0230 P_10=0.0740 <--\n",
      "[2022-11-01 03:05:19,802][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:19,806][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:19,810][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:25,653][onir_pt][DEBUG] [finished] train pairs: [5.84s] [1024it] [175.36it/s]\n",
      "[2022-11-01 03:05:25,661][onir_pt][DEBUG] [finished] training [5.86s]\n",
      "[2022-11-01 03:05:25,665][onir_pt][INFO] training   it=10 loss=0.1810\n",
      "[2022-11-01 03:05:25,669][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:25,673][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:25,678][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:26,154][onir_pt][DEBUG] [finished] batches: [474ms] [125it] [263.73it/s]\n",
      "[2022-11-01 03:05:26,266][onir_pt][DEBUG] [finished] validation [596ms]\n",
      "[2022-11-01 03:05:26,271][onir_pt][INFO] validation it=10 map=0.0106 ndcg=0.0234 P_10=0.0760\n",
      "[2022-11-01 03:05:26,275][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:26,279][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:26,283][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:32,102][onir_pt][DEBUG] [finished] train pairs: [5.81s] [1024it] [176.11it/s]\n",
      "[2022-11-01 03:05:32,110][onir_pt][DEBUG] [finished] training [5.83s]\n",
      "[2022-11-01 03:05:32,114][onir_pt][INFO] training   it=11 loss=0.1800\n",
      "[2022-11-01 03:05:32,118][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:32,123][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:32,127][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:32,595][onir_pt][DEBUG] [finished] batches: [464ms] [125it] [269.15it/s]\n",
      "[2022-11-01 03:05:32,709][onir_pt][DEBUG] [finished] validation [591ms]\n",
      "[2022-11-01 03:05:32,714][onir_pt][INFO] validation it=11 map=0.0104 ndcg=0.0228 P_10=0.0660\n",
      "[2022-11-01 03:05:32,718][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:32,723][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:32,727][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:38,567][onir_pt][DEBUG] [finished] train pairs: [5.84s] [1024it] [175.47it/s]\n",
      "[2022-11-01 03:05:38,575][onir_pt][DEBUG] [finished] training [5.85s]\n",
      "[2022-11-01 03:05:38,579][onir_pt][INFO] training   it=12 loss=0.1756\n",
      "[2022-11-01 03:05:38,583][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:38,587][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:38,591][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:39,055][onir_pt][DEBUG] [finished] batches: [462ms] [125it] [270.44it/s]\n",
      "[2022-11-01 03:05:39,164][onir_pt][DEBUG] [finished] validation [581ms]\n",
      "[2022-11-01 03:05:39,169][onir_pt][INFO] validation it=12 map=0.0106 ndcg=0.0233 P_10=0.0740\n",
      "[2022-11-01 03:05:39,173][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:39,177][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:39,181][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:44,993][onir_pt][DEBUG] [finished] train pairs: [5.81s] [1024it] [176.31it/s]\n",
      "[2022-11-01 03:05:45,001][onir_pt][DEBUG] [finished] training [5.82s]\n",
      "[2022-11-01 03:05:45,005][onir_pt][INFO] training   it=13 loss=0.1812\n",
      "[2022-11-01 03:05:45,009][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:45,013][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:45,017][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:45,482][onir_pt][DEBUG] [finished] batches: [462ms] [125it] [270.67it/s]\n",
      "[2022-11-01 03:05:45,590][onir_pt][DEBUG] [finished] validation [581ms]\n",
      "[2022-11-01 03:05:45,595][onir_pt][INFO] validation it=13 map=0.0105 ndcg=0.0229 P_10=0.0740\n",
      "[2022-11-01 03:05:45,599][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:45,603][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:45,607][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:51,469][onir_pt][DEBUG] [finished] train pairs: [5.86s] [1024it] [174.83it/s]\n",
      "[2022-11-01 03:05:51,476][onir_pt][DEBUG] [finished] training [5.87s]\n",
      "[2022-11-01 03:05:51,481][onir_pt][INFO] training   it=14 loss=0.1850\n",
      "[2022-11-01 03:05:51,484][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:51,488][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:51,493][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:51,961][onir_pt][DEBUG] [finished] batches: [466ms] [125it] [268.22it/s]\n",
      "[2022-11-01 03:05:52,068][onir_pt][DEBUG] [finished] validation [583ms]\n",
      "[2022-11-01 03:05:52,074][onir_pt][INFO] validation it=14 map=0.0106 ndcg=0.0230 P_10=0.0700 <--\n",
      "[2022-11-01 03:05:52,078][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:52,082][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:52,086][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:57,880][onir_pt][DEBUG] [finished] train pairs: [5.79s] [1024it] [176.84it/s]\n",
      "[2022-11-01 03:05:57,888][onir_pt][DEBUG] [finished] training [5.81s]\n",
      "[2022-11-01 03:05:57,892][onir_pt][INFO] training   it=15 loss=0.1800\n",
      "[2022-11-01 03:05:57,896][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:05:57,900][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:57,904][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:05:58,368][onir_pt][DEBUG] [finished] batches: [462ms] [125it] [270.82it/s]\n",
      "[2022-11-01 03:05:58,476][onir_pt][DEBUG] [finished] validation [579ms]\n",
      "[2022-11-01 03:05:58,481][onir_pt][INFO] validation it=15 map=0.0105 ndcg=0.0229 P_10=0.0660\n",
      "[2022-11-01 03:05:58,485][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:05:58,489][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:05:58,493][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:04,307][onir_pt][DEBUG] [finished] train pairs: [5.81s] [1024it] [176.25it/s]\n",
      "[2022-11-01 03:06:04,315][onir_pt][DEBUG] [finished] training [5.83s]\n",
      "[2022-11-01 03:06:04,319][onir_pt][INFO] training   it=16 loss=0.1738\n",
      "[2022-11-01 03:06:04,323][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:04,327][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:04,331][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:04,799][onir_pt][DEBUG] [finished] batches: [465ms] [125it] [268.66it/s]\n",
      "[2022-11-01 03:06:04,907][onir_pt][DEBUG] [finished] validation [584ms]\n",
      "[2022-11-01 03:06:04,912][onir_pt][INFO] validation it=16 map=0.0105 ndcg=0.0233 P_10=0.0700\n",
      "[2022-11-01 03:06:04,916][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:04,920][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:04,924][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:10,769][onir_pt][DEBUG] [finished] train pairs: [5.84s] [1024it] [175.32it/s]\n",
      "[2022-11-01 03:06:10,777][onir_pt][DEBUG] [finished] training [5.86s]\n",
      "[2022-11-01 03:06:10,781][onir_pt][INFO] training   it=17 loss=0.1832\n",
      "[2022-11-01 03:06:10,785][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:10,789][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:10,793][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:11,271][onir_pt][DEBUG] [finished] batches: [476ms] [125it] [262.86it/s]\n",
      "[2022-11-01 03:06:11,377][onir_pt][DEBUG] [finished] validation [592ms]\n",
      "[2022-11-01 03:06:11,382][onir_pt][INFO] validation it=17 map=0.0103 ndcg=0.0228 P_10=0.0680\n",
      "[2022-11-01 03:06:11,386][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:11,390][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:11,394][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:17,237][onir_pt][DEBUG] [finished] train pairs: [5.84s] [1024it] [175.37it/s]\n",
      "[2022-11-01 03:06:17,245][onir_pt][DEBUG] [finished] training [5.86s]\n",
      "[2022-11-01 03:06:17,249][onir_pt][INFO] training   it=18 loss=0.1738\n",
      "[2022-11-01 03:06:17,253][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:17,257][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:17,262][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:17,733][onir_pt][DEBUG] [finished] batches: [469ms] [125it] [266.43it/s]\n",
      "[2022-11-01 03:06:17,840][onir_pt][DEBUG] [finished] validation [586ms]\n",
      "[2022-11-01 03:06:17,845][onir_pt][INFO] validation it=18 map=0.0105 ndcg=0.0230 P_10=0.0660\n",
      "[2022-11-01 03:06:17,849][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:17,853][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:17,857][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:23,734][onir_pt][DEBUG] [finished] train pairs: [5.87s] [1024it] [174.35it/s]\n",
      "[2022-11-01 03:06:23,743][onir_pt][DEBUG] [finished] training [5.89s]\n",
      "[2022-11-01 03:06:23,747][onir_pt][INFO] training   it=19 loss=0.1805\n",
      "[2022-11-01 03:06:23,751][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:23,755][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:23,759][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:24,230][onir_pt][DEBUG] [finished] batches: [467ms] [125it] [267.53it/s]\n",
      "[2022-11-01 03:06:24,338][onir_pt][DEBUG] [finished] validation [587ms]\n",
      "[2022-11-01 03:06:24,343][onir_pt][INFO] validation it=19 map=0.0105 ndcg=0.0229 P_10=0.0660\n",
      "[2022-11-01 03:06:24,347][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:24,351][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:24,355][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:30,169][onir_pt][DEBUG] [finished] train pairs: [5.81s] [1024it] [176.26it/s]\n",
      "[2022-11-01 03:06:30,177][onir_pt][DEBUG] [finished] training [5.83s]\n",
      "[2022-11-01 03:06:30,181][onir_pt][INFO] training   it=20 loss=0.1768\n",
      "[2022-11-01 03:06:30,185][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:30,189][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:30,193][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:30,674][onir_pt][DEBUG] [finished] batches: [478ms] [125it] [261.35it/s]\n",
      "[2022-11-01 03:06:30,782][onir_pt][DEBUG] [finished] validation [597ms]\n",
      "[2022-11-01 03:06:30,787][onir_pt][INFO] validation it=20 map=0.0104 ndcg=0.0228 P_10=0.0640\n",
      "[2022-11-01 03:06:30,791][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:30,796][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:30,800][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:36,639][onir_pt][DEBUG] [finished] train pairs: [5.84s] [1024it] [175.47it/s]\n",
      "[2022-11-01 03:06:36,647][onir_pt][DEBUG] [finished] training [5.85s]\n",
      "[2022-11-01 03:06:36,651][onir_pt][INFO] training   it=21 loss=0.1876\n",
      "[2022-11-01 03:06:36,655][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:36,659][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:36,663][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:37,131][onir_pt][DEBUG] [finished] batches: [465ms] [125it] [268.98it/s]\n",
      "[2022-11-01 03:06:37,240][onir_pt][DEBUG] [finished] validation [584ms]\n",
      "[2022-11-01 03:06:37,245][onir_pt][INFO] validation it=21 map=0.0104 ndcg=0.0228 P_10=0.0640\n",
      "[2022-11-01 03:06:37,249][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:37,253][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:37,257][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:43,036][onir_pt][DEBUG] [finished] train pairs: [5.78s] [1024it] [177.31it/s]\n",
      "[2022-11-01 03:06:43,044][onir_pt][DEBUG] [finished] training [5.79s]\n",
      "[2022-11-01 03:06:43,048][onir_pt][INFO] training   it=22 loss=0.1734\n",
      "[2022-11-01 03:06:43,052][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:43,056][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:43,060][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:43,535][onir_pt][DEBUG] [finished] batches: [472ms] [125it] [265.00it/s]\n",
      "[2022-11-01 03:06:43,643][onir_pt][DEBUG] [finished] validation [590ms]\n",
      "[2022-11-01 03:06:43,648][onir_pt][INFO] validation it=22 map=0.0105 ndcg=0.0229 P_10=0.0660\n",
      "[2022-11-01 03:06:43,652][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:43,656][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:43,660][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:49,602][onir_pt][DEBUG] [finished] train pairs: [5.94s] [1024it] [172.45it/s]\n",
      "[2022-11-01 03:06:49,610][onir_pt][DEBUG] [finished] training [5.95s]\n",
      "[2022-11-01 03:06:49,614][onir_pt][INFO] training   it=23 loss=0.1806\n",
      "[2022-11-01 03:06:49,618][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:49,622][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:49,626][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:50,124][onir_pt][DEBUG] [finished] batches: [495ms] [125it] [252.35it/s]\n",
      "[2022-11-01 03:06:50,235][onir_pt][DEBUG] [finished] validation [617ms]\n",
      "[2022-11-01 03:06:50,240][onir_pt][INFO] validation it=23 map=0.0104 ndcg=0.0232 P_10=0.0680\n",
      "[2022-11-01 03:06:50,244][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:50,248][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:50,252][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:56,231][onir_pt][DEBUG] [finished] train pairs: [5.97s] [1024it] [171.38it/s]\n",
      "[2022-11-01 03:06:56,239][onir_pt][DEBUG] [finished] training [5.99s]\n",
      "[2022-11-01 03:06:56,243][onir_pt][INFO] training   it=24 loss=0.1753\n",
      "[2022-11-01 03:06:56,247][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:06:56,251][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:56,255][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:06:56,733][onir_pt][DEBUG] [finished] batches: [475ms] [125it] [262.94it/s]\n",
      "[2022-11-01 03:06:56,840][onir_pt][DEBUG] [finished] validation [593ms]\n",
      "[2022-11-01 03:06:56,845][onir_pt][INFO] validation it=24 map=0.0105 ndcg=0.0230 P_10=0.0720\n",
      "[2022-11-01 03:06:56,849][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:06:56,854][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:06:56,858][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:02,693][onir_pt][DEBUG] [finished] train pairs: [5.83s] [1024it] [175.60it/s]\n",
      "[2022-11-01 03:07:02,701][onir_pt][DEBUG] [finished] training [5.85s]\n",
      "[2022-11-01 03:07:02,705][onir_pt][INFO] training   it=25 loss=0.1812\n",
      "[2022-11-01 03:07:02,709][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:02,713][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:02,717][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:03,191][onir_pt][DEBUG] [finished] batches: [471ms] [125it] [265.16it/s]\n",
      "[2022-11-01 03:07:03,300][onir_pt][DEBUG] [finished] validation [591ms]\n",
      "[2022-11-01 03:07:03,305][onir_pt][INFO] validation it=25 map=0.0106 ndcg=0.0231 P_10=0.0680\n",
      "[2022-11-01 03:07:03,309][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:03,313][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:03,317][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:09,126][onir_pt][DEBUG] [finished] train pairs: [5.80s] [1024it] [176.43it/s]\n",
      "[2022-11-01 03:07:09,134][onir_pt][DEBUG] [finished] training [5.82s]\n",
      "[2022-11-01 03:07:09,138][onir_pt][INFO] training   it=26 loss=0.1775\n",
      "[2022-11-01 03:07:09,142][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:09,145][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:09,150][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:09,621][onir_pt][DEBUG] [finished] batches: [469ms] [125it] [266.66it/s]\n",
      "[2022-11-01 03:07:09,728][onir_pt][DEBUG] [finished] validation [586ms]\n",
      "[2022-11-01 03:07:09,733][onir_pt][INFO] validation it=26 map=0.0105 ndcg=0.0232 P_10=0.0720\n",
      "[2022-11-01 03:07:09,737][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:09,741][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:09,745][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:15,562][onir_pt][DEBUG] [finished] train pairs: [5.81s] [1024it] [176.15it/s]\n",
      "[2022-11-01 03:07:15,570][onir_pt][DEBUG] [finished] training [5.83s]\n",
      "[2022-11-01 03:07:15,574][onir_pt][INFO] training   it=27 loss=0.1818\n",
      "[2022-11-01 03:07:15,578][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:15,582][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:15,586][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:16,057][onir_pt][DEBUG] [finished] batches: [466ms] [125it] [268.00it/s]\n",
      "[2022-11-01 03:07:16,168][onir_pt][DEBUG] [finished] validation [589ms]\n",
      "[2022-11-01 03:07:16,173][onir_pt][INFO] validation it=27 map=0.0103 ndcg=0.0228 P_10=0.0660\n",
      "[2022-11-01 03:07:16,177][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:16,181][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:16,185][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:22,192][onir_pt][DEBUG] [finished] train pairs: [6.00s] [1024it] [170.57it/s]\n",
      "[2022-11-01 03:07:22,201][onir_pt][DEBUG] [finished] training [6.02s]\n",
      "[2022-11-01 03:07:22,205][onir_pt][INFO] training   it=28 loss=0.1660\n",
      "[2022-11-01 03:07:22,209][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:22,213][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:22,217][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:22,700][onir_pt][DEBUG] [finished] batches: [480ms] [125it] [260.29it/s]\n",
      "[2022-11-01 03:07:22,808][onir_pt][DEBUG] [finished] validation [600ms]\n",
      "[2022-11-01 03:07:22,813][onir_pt][INFO] validation it=28 map=0.0104 ndcg=0.0229 P_10=0.0680\n",
      "[2022-11-01 03:07:22,817][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:22,822][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:22,826][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:28,826][onir_pt][DEBUG] [finished] train pairs: [6.00s] [1024it] [170.77it/s]\n",
      "[2022-11-01 03:07:28,829][onir_pt][DEBUG] [finished] training [6.01s]\n",
      "[2022-11-01 03:07:28,831][onir_pt][INFO] training   it=29 loss=0.1777\n",
      "[2022-11-01 03:07:28,832][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:28,833][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:28,848][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [23ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:29,369][onir_pt][DEBUG] [finished] batches: [520ms] [125it] [240.51it/s]\n",
      "[2022-11-01 03:07:29,477][onir_pt][DEBUG] [finished] validation [645ms]\n",
      "[2022-11-01 03:07:29,482][onir_pt][INFO] validation it=29 map=0.0104 ndcg=0.0228 P_10=0.0680\n",
      "[2022-11-01 03:07:29,486][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:29,490][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:29,494][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:35,484][onir_pt][DEBUG] [finished] train pairs: [5.99s] [1024it] [171.07it/s]\n",
      "[2022-11-01 03:07:35,492][onir_pt][DEBUG] [finished] training [6.00s]\n",
      "[2022-11-01 03:07:35,496][onir_pt][INFO] training   it=30 loss=0.1757\n",
      "[2022-11-01 03:07:35,500][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:35,504][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:35,508][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:36,000][onir_pt][DEBUG] [finished] batches: [490ms] [125it] [255.06it/s]\n",
      "[2022-11-01 03:07:36,107][onir_pt][DEBUG] [finished] validation [607ms]\n",
      "[2022-11-01 03:07:36,112][onir_pt][INFO] validation it=30 map=0.0104 ndcg=0.0226 P_10=0.0620\n",
      "[2022-11-01 03:07:36,116][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:36,120][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:36,124][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:42,105][onir_pt][DEBUG] [finished] train pairs: [5.98s] [1024it] [171.33it/s]\n",
      "[2022-11-01 03:07:42,113][onir_pt][DEBUG] [finished] training [5.99s]\n",
      "[2022-11-01 03:07:42,117][onir_pt][INFO] training   it=31 loss=0.1975\n",
      "[2022-11-01 03:07:42,121][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:42,125][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:42,129][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:42,635][onir_pt][DEBUG] [finished] batches: [503ms] [125it] [248.48it/s]\n",
      "[2022-11-01 03:07:42,743][onir_pt][DEBUG] [finished] validation [622ms]\n",
      "[2022-11-01 03:07:42,748][onir_pt][INFO] validation it=31 map=0.0104 ndcg=0.0232 P_10=0.0640\n",
      "[2022-11-01 03:07:42,752][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:42,756][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:42,760][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:48,794][onir_pt][DEBUG] [finished] train pairs: [6.03s] [1024it] [169.83it/s]\n",
      "[2022-11-01 03:07:48,801][onir_pt][DEBUG] [finished] training [6.05s]\n",
      "[2022-11-01 03:07:48,805][onir_pt][INFO] training   it=32 loss=0.1905\n",
      "[2022-11-01 03:07:48,809][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:48,813][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:48,817][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:49,360][onir_pt][DEBUG] [finished] batches: [540ms] [125it] [231.30it/s]\n",
      "[2022-11-01 03:07:49,466][onir_pt][DEBUG] [finished] validation [657ms]\n",
      "[2022-11-01 03:07:49,471][onir_pt][INFO] validation it=32 map=0.0104 ndcg=0.0229 P_10=0.0700\n",
      "[2022-11-01 03:07:49,475][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:49,479][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:49,483][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:55,668][onir_pt][DEBUG] [finished] train pairs: [6.18s] [1024it] [165.67it/s]\n",
      "[2022-11-01 03:07:55,676][onir_pt][DEBUG] [finished] training [6.20s]\n",
      "[2022-11-01 03:07:55,680][onir_pt][INFO] training   it=33 loss=0.1754\n",
      "[2022-11-01 03:07:55,684][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:07:55,688][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:55,692][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [40ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:07:56,279][onir_pt][DEBUG] [finished] batches: [585ms] [125it] [213.79it/s]\n",
      "[2022-11-01 03:07:56,387][onir_pt][DEBUG] [finished] validation [703ms]\n",
      "[2022-11-01 03:07:56,392][onir_pt][INFO] validation it=33 map=0.0103 ndcg=0.0230 P_10=0.0660\n",
      "[2022-11-01 03:07:56,396][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:07:56,400][onir_pt][DEBUG] [starting] training\n",
      "[2022-11-01 03:07:56,404][onir_pt][DEBUG] [starting] train pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train pairs:   0%|          | 0/1024 [26ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:08:02,669][onir_pt][DEBUG] [finished] train pairs: [6.26s] [1024it] [163.58it/s]\n",
      "[2022-11-01 03:08:02,677][onir_pt][DEBUG] [finished] training [6.28s]\n",
      "[2022-11-01 03:08:02,681][onir_pt][INFO] training   it=34 loss=0.1618\n",
      "[2022-11-01 03:08:02,685][onir_pt][DEBUG] [starting] validation\n",
      "[2022-11-01 03:08:02,689][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:08:02,693][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/125 [27ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:08:03,243][onir_pt][DEBUG] [finished] batches: [548ms] [125it] [227.97it/s]\n",
      "[2022-11-01 03:08:03,350][onir_pt][DEBUG] [finished] validation [665ms]\n",
      "[2022-11-01 03:08:03,355][onir_pt][INFO] validation it=34 map=0.0104 ndcg=0.0232 P_10=0.0640\n",
      "[2022-11-01 03:08:03,359][onir_pt][INFO] early stopping; model reverting back to it=14\n",
      "[2022-11-01 03:08:06,514][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:08:06,516][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/375 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:08:07,743][onir_pt][DEBUG] [finished] batches: [1.22s] [375it] [306.12it/s]\n",
      "[2022-11-01 03:08:08,658][onir_pt][ERROR] gpu=True, but CUDA is not available. Falling back on CPU.\n",
      "[2022-11-01 03:08:08,660][onir_pt][DEBUG] [starting] batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batches:   0%|          | 0/375 [14ms<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-11-01 03:08:09,837][onir_pt][DEBUG] [finished] batches: [1.18s] [375it] [318.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>P.10</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br</td>\n",
       "      <td>0.067211</td>\n",
       "      <td>0.165279</td>\n",
       "      <td>0.570299</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>81.068571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm25</td>\n",
       "      <td>0.073811</td>\n",
       "      <td>0.172321</td>\n",
       "      <td>0.594773</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>60.066404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>br &gt;&gt; knrm</td>\n",
       "      <td>0.065974</td>\n",
       "      <td>0.164825</td>\n",
       "      <td>0.540699</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>144.810106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bm25 &gt;&gt; knrm</td>\n",
       "      <td>0.071050</td>\n",
       "      <td>0.170254</td>\n",
       "      <td>0.523204</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>136.906838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name       map      ndcg  ndcg_cut.10      P.10         mrt\n",
       "0            br  0.067211  0.165279     0.570299  0.633333   81.068571\n",
       "1          bm25  0.073811  0.172321     0.594773  0.660000   60.066404\n",
       "2    br >> knrm  0.065974  0.164825     0.540699  0.633333  144.810106\n",
       "3  bm25 >> knrm  0.071050  0.170254     0.523204  0.620000  136.906838"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANK_CUTOFF = 10\n",
    "SEED=42\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "topics = dataset.get_topics(variant='description')\n",
    "qrels = dataset.get_qrels()\n",
    "\n",
    "tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n",
    "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)\n",
    "\n",
    "#del knrm # clear out memory from KNRM (useful for GPU)\n",
    "knrm = onir_pt.reranker('knrm', 'wordvec_hash', text_field='abstract')\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "\n",
    "knrm_pipeline = (pt.BatchRetrieve(indexref) % 100 # get top 100 results\n",
    "            >> pt.text.get_text(dataset, 'abstract') # fetch the document text\n",
    "            >> pt.apply.generic(lambda df: df.rename(columns={'text': 'abstract'})) # rename columns\n",
    "            >> knrm) # apply neural re-ranker\n",
    "knrm_pipeline.fit(train_topics,qrels, valid_topics,qrels)\n",
    "\n",
    "\n",
    "bm25_pipeline = (pt.BatchRetrieve(indexref, wmodel=\"BM25\") % 100 # get top 100 results\n",
    "            >> pt.text.get_text(dataset, 'abstract') # fetch the document text\n",
    "            >> pt.apply.generic(lambda df: df.rename(columns={'text': 'abstract'})) # rename columns\n",
    "            >> knrm) # apply neural re-ranker\n",
    "bm25_pipeline.fit(train_topics,qrels, valid_topics,qrels)\n",
    "\n",
    "\n",
    "pt.Experiment(\n",
    "  [br % 100, bm25 % 100, knrm_pipeline, bm25_pipeline],\n",
    "  test_topics,\n",
    "  qrels,\n",
    "  eval_metrics=[\"map\", \"ndcg\", 'ndcg_cut.10', 'P.10', 'mrt'],\n",
    "  names=[\"br\", \"bm25\", \"br >> knrm\", \"bm25 >> knrm\"]\n",
    ")\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5edb762c8f1f97e30be1693b3bc33ef875ebeea771af1e2528afd5961b13c703"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02765e4f002142a9835aabf3e5150c8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0d64138cb8e44218ce0c18fbaf44cd0",
       "IPY_MODEL_44eee719e6794b4abf741c042d184e76",
       "IPY_MODEL_d1a059bca1f84d5e90f95e4b8fee47e8"
      ],
      "layout": "IPY_MODEL_a9e05b46cef04c9687dc45889f11a656"
     }
    },
    "03205af8db554ed8acfd285d9d8f3872": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cc162ed4f424b5190d5e658a29d758a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1334426445c84c0e83e73e2703b4d3ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1763b73855a74aae9b887508d20d0cd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20475c20e3d84772941d0d08ec99674b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20789d42cd9247a689816e73eec22eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a503a4c2db344890b6d9a865642e9ea7",
       "IPY_MODEL_9005f45d8f7742d8ae68b3ecf4afd2e7",
       "IPY_MODEL_67fb386486244f52903806582b64882f"
      ],
      "layout": "IPY_MODEL_20475c20e3d84772941d0d08ec99674b"
     }
    },
    "2320258836e246bab3ef337e449e3011": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "298015f6a4f94124923c87c647e7fac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5160c5a8f1c4d4a9cdb40a2fba834f6",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76ebb395c6e54586b8dfcf82531d8720",
      "value": 1250
     }
    },
    "37de10336b424425b8f38240db4e5956": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "380f8933c57f4b9486da05b2becfc18d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "420321132ab349eaa56fce49c87b05b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44eee719e6794b4abf741c042d184e76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37de10336b424425b8f38240db4e5956",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cc162ed4f424b5190d5e658a29d758a",
      "value": 1250
     }
    },
    "485375142e0843c6b45036f1aa397754": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d611a1adc704300b1f2866a12f50f43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51622d428af649de9418789d44d3c3d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "52cc333559b34d8f9eba36bc8c754cdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "576320a691254eed82a9405f63d086f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59a9941b61b74e4ca7d83ac0cc7a9229": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b0c9e8cc35e494ebdce2b19da4fd529": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f2552cf4bff484e8fa267b316e5187c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67fb386486244f52903806582b64882f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d611a1adc704300b1f2866a12f50f43",
      "placeholder": "​",
      "style": "IPY_MODEL_8e5777f558d74059af1e4681ff354302",
      "value": " 670/1250 [1:00:19&lt;52:13,  5.40s/it]"
     }
    },
    "68112ad488014d3c9e29a2ebf230ad27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69938afc305f4151913e9ef85049f5ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76ebb395c6e54586b8dfcf82531d8720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a7a8edd8a5748b991cb14eda85e3456": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b0c9e8cc35e494ebdce2b19da4fd529",
      "placeholder": "​",
      "style": "IPY_MODEL_e0777ba7cc804e089cf3de10cb62c45b",
      "value": " 192509/192509 [01:12&lt;0ms, 3074.34it/s]"
     }
    },
    "863e39b5666b4047a1c5bdb51328331b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_934d41cace5a432e9775261987f20777",
       "IPY_MODEL_298015f6a4f94124923c87c647e7fac4",
       "IPY_MODEL_d0b64a8ca745479e81c8282a528d369c"
      ],
      "layout": "IPY_MODEL_51622d428af649de9418789d44d3c3d8"
     }
    },
    "8e5777f558d74059af1e4681ff354302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9005f45d8f7742d8ae68b3ecf4afd2e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad7410f8f8d7429ab9ded6c18107efff",
      "max": 1250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa4a3a71b642475fa9fb868eb9354b34",
      "value": 670
     }
    },
    "934d41cace5a432e9775261987f20777": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03205af8db554ed8acfd285d9d8f3872",
      "placeholder": "​",
      "style": "IPY_MODEL_420321132ab349eaa56fce49c87b05b4",
      "value": "batches:  98%"
     }
    },
    "a0d64138cb8e44218ce0c18fbaf44cd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_576320a691254eed82a9405f63d086f1",
      "placeholder": "​",
      "style": "IPY_MODEL_59a9941b61b74e4ca7d83ac0cc7a9229",
      "value": "batches:  98%"
     }
    },
    "a503a4c2db344890b6d9a865642e9ea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_485375142e0843c6b45036f1aa397754",
      "placeholder": "​",
      "style": "IPY_MODEL_52cc333559b34d8f9eba36bc8c754cdd",
      "value": "batches:  54%"
     }
    },
    "a9e05b46cef04c9687dc45889f11a656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "aa4a3a71b642475fa9fb868eb9354b34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad7410f8f8d7429ab9ded6c18107efff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bda29af558d3441aba1314ad63971f18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1334426445c84c0e83e73e2703b4d3ec",
      "placeholder": "​",
      "style": "IPY_MODEL_68112ad488014d3c9e29a2ebf230ad27",
      "value": "cord19/trec-covid documents: 100%"
     }
    },
    "d0b64a8ca745479e81c8282a528d369c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff10e5edb9264bf7b82884eea1cdd48c",
      "placeholder": "​",
      "style": "IPY_MODEL_fef95649700b463981819d0b5dfacc9c",
      "value": " 1226/1250 [4.80s&lt;94ms, 255.31it/s]"
     }
    },
    "d1a059bca1f84d5e90f95e4b8fee47e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_380f8933c57f4b9486da05b2becfc18d",
      "placeholder": "​",
      "style": "IPY_MODEL_69938afc305f4151913e9ef85049f5ea",
      "value": " 1219/1250 [5.02s&lt;128ms, 243.00it/s]"
     }
    },
    "e0777ba7cc804e089cf3de10cb62c45b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5160c5a8f1c4d4a9cdb40a2fba834f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0c27da6a4564ca3978b62fa0a94ac01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2320258836e246bab3ef337e449e3011",
      "max": 192509,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f2552cf4bff484e8fa267b316e5187c",
      "value": 192509
     }
    },
    "f69437f61cc049679f40e3f7d460063b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bda29af558d3441aba1314ad63971f18",
       "IPY_MODEL_f0c27da6a4564ca3978b62fa0a94ac01",
       "IPY_MODEL_7a7a8edd8a5748b991cb14eda85e3456"
      ],
      "layout": "IPY_MODEL_1763b73855a74aae9b887508d20d0cd1"
     }
    },
    "fef95649700b463981819d0b5dfacc9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff10e5edb9264bf7b82884eea1cdd48c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
