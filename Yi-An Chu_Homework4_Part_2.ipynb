{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZegaoMgrYwh"
      },
      "source": [
        "# Homework 4, Part 2\n",
        "\n",
        "In Part 1, we saw how to create a bi-encoder to estimate the relevance of a query-document pair and generate these relevance scores. In Part 2, we'll see how to integrate those scores into a learning to rank (L2R) model with a few features.\n",
        "\n",
        "For this part, you are going to:\n",
        "1. Create the dataset ready to use for Pyterrier.\n",
        "2. integrate the cosine similarity you have got in part 1 into the features of learning to rank models.\n",
        "\n",
        "\n",
        "Learning goals for Homework 4, Part 2:\n",
        "* Improve familiarity with installing and running Pyterrier code\n",
        "* Learn how to use L2R models in Pyterrier\n",
        "* Learn how to add custom features to L2R models with Pyterrier.\n",
        "* Deepen your understanding of how different models perform in mixed-domain settings (e.g., text queries / code docs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8GcsbDrXnMW"
      },
      "source": [
        "### Step 0: install things as needed\n",
        "\n",
        "In case you didn't do any of Homework 3 (which was extra credit), please be sure to have the following libraries installed and ready. The installation command is commented out for now but uncomment and run each as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRzIlIKAXnMY",
        "outputId": "3475f613-689a-44bb-ee76-bee7410acd4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastrank in /usr/local/lib/python3.8/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fastrank) (1.21.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from fastrank) (22.1.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fastrank) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fastrank) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->lightgbm) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-terrier in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.2.0)\n",
            "Requirement already satisfied: ir-datasets>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from python-terrier) (0.5.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from python-terrier) (0.3.6)\n",
            "Requirement already satisfied: pyjnius>=1.4.2 in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.4.2)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.2.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from python-terrier) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from python-terrier) (4.64.1)\n",
            "Requirement already satisfied: nptyping==1.4.4 in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.4.4)\n",
            "Requirement already satisfied: ir-measures>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from python-terrier) (0.3.1)\n",
            "Requirement already satisfied: matchpy in /usr/local/lib/python3.8/dist-packages (from python-terrier) (0.5.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.21.6)\n",
            "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /usr/local/lib/python3.8/dist-packages (from python-terrier) (0.5.5)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (from python-terrier) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from python-terrier) (2.11.3)\n",
            "Requirement already satisfied: chest in /usr/local/lib/python3.8/dist-packages (from python-terrier) (0.2.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (from python-terrier) (0.0.post1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from python-terrier) (0.12.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from python-terrier) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.3.5)\n",
            "Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.9.1)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.5)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (6.0)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (3.1.4)\n",
            "Requirement already satisfied: lz4>=3.1.1 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.0.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.6.3)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.1)\n",
            "Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.9)\n",
            "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.8/dist-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pyjnius>=1.4.2->python-terrier) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->python-terrier) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->python-terrier) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->python-terrier) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->python-terrier) (2022.9.24)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from chest->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from deprecated->python-terrier) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->python-terrier) (2.0.1)\n",
            "Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from matchpy->python-terrier) (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->python-terrier) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->python-terrier) (2022.6)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->python-terrier) (0.5.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastrank\n",
        "!pip install lightgbm\n",
        "!pip install python-terrier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCChI82b5QgT"
      },
      "source": [
        "# Task 1: Creating a dataset with precomputed features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrEsm8o1xr86"
      },
      "source": [
        "## Task 1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e98PFUU7xx4e"
      },
      "source": [
        "Load in the dataset used for evaluation as a pandas data frame, which is in `final_evaluation_set.csv`. Then print the number of unique queries (99), unique code-documents in the dataset (958) to verify it was loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J330BEh1XnMe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "vkSYYeQ1XnMf",
        "outputId": "b19fa1d5-fe8f-4dea-8adc-dc2a9cc1df40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "958\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    docno                                               text\n",
              "0       1  def linear_regression(self, target, regression...\n",
              "1       2  def ConsoleType(t=gtk.TextView): class console...\n",
              "2       3  def _do_post(self, url, **kwargs): \"\"\" Convini...\n",
              "3       4  def readcsv(fn): \"\"\" Wrapper to read arbitrary...\n",
              "4       5  def scatter(self, ax, X, Y, Z=None, color=Tang...\n",
              "..    ...                                                ...\n",
              "953   954  def decode_longitude(self, longitude): match =...\n",
              "954   955  def unzip_unicode(output, version): \"\"\"Unzip t...\n",
              "955   956  def get_enum_from_name(self, enum_name): \"\"\" R...\n",
              "956   957  def __call__(self, value): for substring in se...\n",
              "957   958  def tag_to_dict(html): \"\"\"Extract tag's attrib...\n",
              "\n",
              "[958 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a85ffba3-87ff-4528-b168-1ae4c57fafc2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docno</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>def linear_regression(self, target, regression...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>def ConsoleType(t=gtk.TextView): class console...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>def _do_post(self, url, **kwargs): \"\"\" Convini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>def readcsv(fn): \"\"\" Wrapper to read arbitrary...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>def scatter(self, ax, X, Y, Z=None, color=Tang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>954</td>\n",
              "      <td>def decode_longitude(self, longitude): match =...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>955</td>\n",
              "      <td>def unzip_unicode(output, version): \"\"\"Unzip t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>956</td>\n",
              "      <td>def get_enum_from_name(self, enum_name): \"\"\" R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>957</td>\n",
              "      <td>def __call__(self, value): for substring in se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>958</td>\n",
              "      <td>def tag_to_dict(html): \"\"\"Extract tag's attrib...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>958 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a85ffba3-87ff-4528-b168-1ae4c57fafc2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a85ffba3-87ff-4528-b168-1ae4c57fafc2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a85ffba3-87ff-4528-b168-1ae4c57fafc2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "# TODO\n",
        "finalFile = pd.read_csv('final_evaluation_set.csv')\n",
        "finalFile = pd.DataFrame(finalFile)\n",
        "# finalFile.insert(0, 'docid', range(len(finalFile)))\n",
        "# finalFile['docid'] = finalFile['docid'].astype(str)\n",
        "finalFile = finalFile.rename(columns = {'code':'text'})\n",
        "\n",
        "uni_query = set(finalFile['Query'])\n",
        "uni_code = set(finalFile['text'])\n",
        "\n",
        "df_code = pd.DataFrame(list(uni_code), columns=['text'])\n",
        "df_code.insert(0, 'docno', range(1,len(df_code)+1))\n",
        "df_code['docno'] = df_code['docno'].astype(str)\n",
        "\n",
        "print(len(uni_query))\n",
        "print(len(df_code))\n",
        "df_code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgalx8xSyUuN"
      },
      "source": [
        "## Task 1.2: Creating an index  (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxRnZjD0yWsO"
      },
      "source": [
        "Since the code documents are text, we can still create an index to store them (just like regular documents before). Before, we mostly used pre-built indices or loaded them from file. In this part, you'll see how to create your own index from a pandas dataframe. \n",
        "\n",
        "The rough steps are as follows:\n",
        "* Start pyterrier\n",
        "* Map each unique code document to a unique string identifier (keep this around in a dictionary!)\n",
        "* Create a pandas DataFrame of each unique code-document with two columns:\n",
        "  * `text` containing the contents of the code-document \n",
        "  * `docid` a unique string identifier for that code-document\n",
        "* use pyterrier's [`DFIndexer`](https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html) to create an index from the data frame.\n",
        "\n",
        "Once you're finished with these steps, print the collection statistics, which should look something like this:\n",
        "```\n",
        "Number of documents: 958\n",
        "Number of terms: 4929\n",
        "Number of postings: 26358\n",
        "Number of fields: 0\n",
        "Number of tokens: 65017\n",
        "Field names: []\n",
        "Positions:   false\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z758Ts0fXnND"
      },
      "outputs": [],
      "source": [
        "# TODO: Set this based on where Java is installed\n",
        "!export JAVA_HOME=/usr/lib/jvm/java-18-openjdk-amd64/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fej57OYaDfv",
        "outputId": "91dcdefe-b43f-4da8-d9d2-18c13a3f6ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/java\n"
          ]
        }
      ],
      "source": [
        "!which java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh1F3nVzXnNF",
        "outputId": "66683c7b-5cdb-4ace-fa75-324aea064764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 958\n",
            "Number of terms: 4929\n",
            "Number of postings: 26358\n",
            "Number of fields: 0\n",
            "Number of tokens: 65017\n",
            "Field names: []\n",
            "Positions:   false\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "import pyterrier as pt\n",
        "import os\n",
        "if not pt.started():\n",
        "    pt.init()\n",
        "    \n",
        "index_dir = './final_index'\n",
        "indexer = pt.DFIndexer(index_dir, overwrite=True)\n",
        "index_ref = indexer.index(df_code[\"text\"], df_code[\"docno\"])\n",
        "index_ref.toString()\n",
        "\n",
        "index = pt.IndexFactory.of(index_ref)\n",
        "\n",
        "print(index.getCollectionStatistics().toString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYYzIVPfzXqo"
      },
      "source": [
        "## Task 1.3: Preparing the query data\n",
        "\n",
        "We'll be using Pyterrier's `Experiment` framework to do our evaluation so we'll need to organize our queries in the test set into a pandas `DataFrame`. Create a new dataframe for all unique queries with two columns:\n",
        "* `query` the text of the query\n",
        "* `qid` a unique string identifier for that query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "m4ATKtaJ9cl7",
        "outputId": "41fc1360-8e2b-40ad-f191-b8ddee975564"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   qid                               query\n",
              "0    1                 get executable path\n",
              "1    2                         format date\n",
              "2    3                encrypt aes ctr mode\n",
              "3    4              json to xml conversion\n",
              "4    5                httpclient post json\n",
              "..  ..                                 ...\n",
              "94  95      extract data from html content\n",
              "95  96                  html encode string\n",
              "96  97  finding time elapsed using a timer\n",
              "97  98                 convert int to bool\n",
              "98  99         parse command line argument\n",
              "\n",
              "[99 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee35cb1d-afcf-4a63-9cf3-7fd2952d7b47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>get executable path</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>format date</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>encrypt aes ctr mode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>json to xml conversion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>httpclient post json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>95</td>\n",
              "      <td>extract data from html content</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>96</td>\n",
              "      <td>html encode string</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>97</td>\n",
              "      <td>finding time elapsed using a timer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>98</td>\n",
              "      <td>convert int to bool</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>99</td>\n",
              "      <td>parse command line argument</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee35cb1d-afcf-4a63-9cf3-7fd2952d7b47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee35cb1d-afcf-4a63-9cf3-7fd2952d7b47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee35cb1d-afcf-4a63-9cf3-7fd2952d7b47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "# TODO\n",
        "\n",
        "query_df = pd.DataFrame(list(uni_query), columns=['query'])\n",
        "query_df.insert(0, 'qid', range(1,len(query_df)+1))\n",
        "query_df['qid'] = query_df['qid'].astype(str)\n",
        "query_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9xA-O3l1yoS"
      },
      "source": [
        "## Task 1.4: Preparing the Evaluation data\n",
        "\n",
        "In the final step, we'll create a single data frame that contains the queries, documents, and true relevance scores, which we'll use to evaluate our models using `pt.Experiment`. Your dataframe should have three columns:\n",
        "* `qid` the unique string identifier for a query\n",
        "* `docno` the unique string identifier for a code-document\n",
        "* `label` the relevance score for that query-document pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "s-FIvfDe-ZoB"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "final_df = finalFile[['Query', 'text', 'relevance']]\n",
        "# print(final_df)\n",
        "# final_df[final_df['Query'] == ]\n",
        "\n",
        "# qid_docno_dict = {}\n",
        "qid_docno = []\n",
        "\n",
        "\n",
        "def lookup_row(row):\n",
        "  a = []\n",
        "  qid = query_df[query_df['query'] == row['Query']]['qid']\n",
        "  docno = df_code[df_code['text'] == row['text']]['docno']\n",
        "  # qid_docno_dict[int(qid), int(docno)] = int(row['relevance'])\n",
        "  a.extend(qid)\n",
        "  a.extend(docno)\n",
        "  a.extend([row['relevance']])\n",
        "  # print(a)\n",
        "  qid_docno.append(a)\n",
        "\n",
        "bb = final_df.apply(lookup_row, axis = 1)\n",
        "qrels_df = pd.DataFrame(qid_docno, columns = ['qid','docno', 'label'])\n",
        "\n",
        "# all_df = []\n",
        "# for q in query_df['qid']:\n",
        "#   for d in df_code['docno']:\n",
        "#     if (int(q), int(d)) in qid_docno_dict:\n",
        "#       all_df.append([q,d,int(qid_docno_dict[int(q), int(d)])])\n",
        "#     else:\n",
        "#       all_df.append([q,d,''])\n",
        "# qrels_df = pd.DataFrame(all_df, columns = ['qid','docno', 'label'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnIdJWty5LcI"
      },
      "source": [
        "# Task 2: Learning to Rank\n",
        "\n",
        "The steps in Task 2 will have you running some evaluations and setting up a Learning to Rank model that we'll extend later to incorporate the bi-encoder features.\n",
        "\n",
        "First, we'll split our labeled query-document data into train, development, and test sets so we can train models and evaluate unsupervised models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "4iJBB7rrXnNc"
      },
      "outputs": [],
      "source": [
        "SEED=42\n",
        "from sklearn.model_selection import train_test_split\n",
        "tr_va_topics, test_topics = train_test_split(query_df, test_size=30, random_state=SEED)\n",
        "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=10, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1Zl0NVF3DSl"
      },
      "source": [
        "## Task 3.1: Test baseline models (5 points)\n",
        "\n",
        "In this initial step, create two `BatchRetrieve` rankers that use \"BM25\" or \"TF_IDF\" and run an `pt.Experiment` using them on the code index, using \"map\" and \"ndcg\" to evaluate their performance. We'll evaluate these only on the test data (no hyperparameter fine-tuning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "kpVQoPjf_Ie8",
        "outputId": "4233b52f-1dfc-4384-9158-50f4b9797a0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         name      map      ndcg\n",
              "0    BR(BM25)  0.76065  0.823841\n",
              "1  BR(TF_IDF)  0.76082  0.826136"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3321076-6f7c-4301-a06d-dfccca75aa2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>ndcg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BR(BM25)</td>\n",
              "      <td>0.76065</td>\n",
              "      <td>0.823841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BR(TF_IDF)</td>\n",
              "      <td>0.76082</td>\n",
              "      <td>0.826136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3321076-6f7c-4301-a06d-dfccca75aa2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3321076-6f7c-4301-a06d-dfccca75aa2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3321076-6f7c-4301-a06d-dfccca75aa2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "# TODO\n",
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
        "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
        "\n",
        "pt.Experiment(\n",
        "    [bm25, tfidf],\n",
        "    query_df,\n",
        "    qrels_df,\n",
        "    eval_metrics=[\"map\", \"ndcg\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTRT5STU5DNP"
      },
      "source": [
        "## Task 3.2: Creating our first pipeline (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZKm-fDK5gIL"
      },
      "source": [
        "Let's start getting more complex with our pipelines. Create a feature pipeline that has three features:\n",
        "1.   the BM25 code score;\n",
        "2.   the TF-IDF code score;\n",
        "3.   the coordinate match score for the query--i.e. how many query terms appear in the code;\n",
        "\n",
        "We'll use these features later in learning to rank. Fo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "BCjbuTRHFUzy"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "\n",
        "ltr_feats1 = bm25 >> pt.transformer.IdentityTransformer() ** tfidf ** pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
        "# qrels = qrels_df.rename(columns = {'label':'score'})\n",
        "qrels = qrels_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrU8hJ-q6VTP"
      },
      "source": [
        "## Setting up the Learning to Rank (L2R) models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu8tqrxn6sRr"
      },
      "source": [
        "For the next part, you won't need to write any code (we've done it for you) but you will need to run the cells to train a few different kinds of L2R models on the training set. Each of the models captures a different kind of L2R that we talked about.\n",
        "\n",
        "Train the following three models on our training set:\n",
        " - random forests from `scikit-learn`, a pointwise regression tree technique\n",
        " - coordinate ascent from FastRank, a listwise linear technique\n",
        " - LambdaMART from LightGBM, a listwise regression tree technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m79Yflq0Fu99",
        "outputId": "e439d67f-382a-4249-d76b-b42db1e91473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.72 s, sys: 76.9 ms, total: 7.8 s\n",
            "Wall time: 5.2 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    3.4s finished\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
        "\n",
        "rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(rf)\n",
        "\n",
        "%time rf_pipe.fit(train_topics, qrels)\n",
        "\n",
        "# print(qrels)\n",
        "# %time rf_pipe.fit(train_topics, qrels_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NphW4hlFzVA",
        "outputId": "03bc9bd7-0cf0-441c-8303-c06ee325acb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.12 s, sys: 22.2 ms, total: 4.14 s\n",
            "Wall time: 2.99 s\n"
          ]
        }
      ],
      "source": [
        "import fastrank\n",
        "train_request = fastrank.TrainRequest.coordinate_ascent()\n",
        "\n",
        "params = train_request.params\n",
        "params.init_random = True\n",
        "params.normalize = True\n",
        "params.seed = 1234567\n",
        "\n",
        "ca_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
        "\n",
        "%time ca_pipe.fit(train_topics, qrels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9nYe5q4GPk3",
        "outputId": "9ee27939-abcf-44c5-da03-db05df61f1b3",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's ndcg@20: 0.586793\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's ndcg@20: 0.702743\n",
            "[3]\tvalid_0's ndcg@20: 0.707713\n",
            "[4]\tvalid_0's ndcg@20: 0.676361\n",
            "[5]\tvalid_0's ndcg@20: 0.700949\n",
            "[6]\tvalid_0's ndcg@20: 0.683647\n",
            "[7]\tvalid_0's ndcg@20: 0.699805\n",
            "[8]\tvalid_0's ndcg@20: 0.696416\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's ndcg@20: 0.707713\n",
            "CPU times: user 2.25 s, sys: 93 ms, total: 2.34 s\n",
            "Wall time: 2.22 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# this configures LightGBM as LambdaMART\n",
        "lmart_l = lgb.LGBMRanker(\n",
        "    task=\"train\",\n",
        "    silent=False,\n",
        "    min_data_in_leaf=1,\n",
        "    min_sum_hessian_in_leaf=1,\n",
        "    max_bin=255,\n",
        "    num_leaves=31,\n",
        "    objective=\"lambdarank\",\n",
        "    metric=\"ndcg\",\n",
        "    ndcg_eval_at=[10],\n",
        "    ndcg_at=[10],\n",
        "    eval_at=[10],\n",
        "    learning_rate= .1,\n",
        "    importance_type=\"gain\",\n",
        "    num_iterations=100,\n",
        "    early_stopping_rounds=5\n",
        ")\n",
        "\n",
        "lmart_x_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[20]})\n",
        "\n",
        "%time lmart_x_pipe.fit(train_topics, qrels, valid_topics, qrels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYfocRg2XnPe"
      },
      "source": [
        "## Task 3.4: Comparing L2R performance (10 points)\n",
        "\n",
        "Now that we have all of our models, let's compare them with the baselines we had before. Run another `Experiment` that compare the three L2R models with the two baselines (BM25 and tf-idf). This time, we'll add \"ndcg_cut_10\" to see their performance on just the top 10 docs and \"mrt\" to see how fast the models are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "AKS9nTDvGjnz",
        "outputId": "e0d4705c-9464-40e3-9452-2f5eeb4ddc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           name       map      ndcg  ndcg_cut_10        mrt\n",
              "0          bm25  0.760650  0.823841     0.740103   3.897158\n",
              "1         tfidf  0.760820  0.826136     0.740142   3.757861\n",
              "2       ca_pipe  0.765443  0.832403     0.745021  38.839609\n",
              "3       rf_pipe  0.817961  0.886145     0.825310  45.126647\n",
              "4  lmart_x_pipe  0.730713  0.810350     0.713836  28.634719"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44ce1c03-22c7-4a86-baa4-c027f721bfdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <th>mrt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bm25</td>\n",
              "      <td>0.760650</td>\n",
              "      <td>0.823841</td>\n",
              "      <td>0.740103</td>\n",
              "      <td>3.897158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tfidf</td>\n",
              "      <td>0.760820</td>\n",
              "      <td>0.826136</td>\n",
              "      <td>0.740142</td>\n",
              "      <td>3.757861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ca_pipe</td>\n",
              "      <td>0.765443</td>\n",
              "      <td>0.832403</td>\n",
              "      <td>0.745021</td>\n",
              "      <td>38.839609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rf_pipe</td>\n",
              "      <td>0.817961</td>\n",
              "      <td>0.886145</td>\n",
              "      <td>0.825310</td>\n",
              "      <td>45.126647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lmart_x_pipe</td>\n",
              "      <td>0.730713</td>\n",
              "      <td>0.810350</td>\n",
              "      <td>0.713836</td>\n",
              "      <td>28.634719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44ce1c03-22c7-4a86-baa4-c027f721bfdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44ce1c03-22c7-4a86-baa4-c027f721bfdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44ce1c03-22c7-4a86-baa4-c027f721bfdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "# TODO\n",
        "\n",
        "pt.Experiment(\n",
        "    [bm25 , tfidf, ca_pipe, rf_pipe , lmart_x_pipe ],\n",
        "    query_df,\n",
        "    qrels,\n",
        "    names = ['bm25', 'tfidf', 'ca_pipe', 'rf_pipe', 'lmart_x_pipe'],\n",
        "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7woPDAu_XnPg"
      },
      "source": [
        "# Task 4: Incorporating new features\n",
        "\n",
        "We didn't expect those approaches to do too well since queries might not reflect the content in the code-documents. But our bi-encoder model knows how to compare both! In Task 4's steps, you'll incorporate it's relevance predictions into the model as another feature.\n",
        "\n",
        "**Note**: For your course projects, if you use Pyterrier, this code should give you some idea of how to incorporate ranking features (or other information) that you've calculated from elsewhere."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASZdKTPG675L"
      },
      "source": [
        "## Task 4.1 Loading in the precomputed relevance data\n",
        "\n",
        "Read in the dataframe with the bi-encoder's estimated relevance scores for each query-document pair (i.e., its cosine similarity), which we produced in Part 1. The length of the dataframe should be (number of unique query) * (number of unique documents)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "uiuB3OWRXnPg"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "import heapq\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "bi_encoder = pd.read_csv('bi-encoder.csv')\n",
        "bi_encoder['sim'].astype('float')\n",
        "bi_encoder = bi_encoder.rename(columns = {'sim':'label'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQx1n6BB7OMh"
      },
      "source": [
        "## Task 4.2: Adding new features (10 points)\n",
        "\n",
        "Once we have our bi-encoder estimates, we'll create a new pipeline that adds the score as a new feature. Recall that Pyterrier's [Pipeline](https://pyterrier.readthedocs.io/en/latest/pipeline_examples.html) is a transformation on a pandas `DataFrame` object. For us, that means we can write a function that operates on each row of the data frame and use pyterrier's [`apply`](https://pyterrier.readthedocs.io/en/latest/apply.html) (whhich is much like pand'as [`apply`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html)). Specifically, we'll write some code that for a given row with a document and query, looks up the precomputed relevance score.\n",
        "\n",
        "While there's many ways to do this, your steps should probably look something like this:\n",
        "* Create some data structure that can map a tuple of the query id and document id to the bi-encoder's relevance score\n",
        "* Write a function takes in a row from a `DataFrame` and uses the query id and document id in the row's columns to look up the bi-encoder's relevance.\n",
        "* Copy and extend your earlier pipeline by adding one new feature that uses pyterrier's `apply` function with your new function. Call this new pipeline `bienc_ltr_feats` so the later training functions can use it\n",
        "\n",
        "Once you have this pipeline in place, use the code below to retrain the models. \n",
        "\n",
        "Add the feature of cosine similarity between query and code embedding into the feaure pipeline. Train the three models and run the experiements again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "Qvy1WjA-HdUl"
      },
      "outputs": [],
      "source": [
        "from decimal import localcontext\n",
        "# TODO\n",
        "# ltr_feats1 = bm25 >> pt.transformer.IdentityTransformer() ** tfidf ** pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
        "\n",
        "bi_encoder_dict = {}\n",
        "def _to_dict(row):\n",
        "  bi_encoder_dict[int(row['qid']), int(row['docno'])] = float(row['label'])\n",
        "bi_encoder.apply(_to_dict,axis = 1)\n",
        "\n",
        "\n",
        "def lookup_fct(key):\n",
        "  return bi_encoder_dict[key]\n",
        "bienc_ltr_feats =  bm25 >> pt.transformer.IdentityTransformer() ** tfidf  ** (pt.apply.lookup_fct(lambda row: (row['qid'], row['docno']))) ** pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
        "\n",
        "# def lookup_fct(row):\n",
        "#   r = dict(row)\n",
        "#   key = (int(r['qid']), int(r['docno']))\n",
        "#   return bi_encoder_dict[key]\n",
        "# row = {'qid':'2', 'docno':'5'}\n",
        "# a = lookup_fct(row)\n",
        "# a\n",
        "# bienc_ltr_feats =  bm25 >> pt.transformer.IdentityTransformer() ** tfidf  ** (bm25 >> pt.apply.doc_score(lookup_fct)) ** pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
        "# bienc_ltr_feats = ltr_feats1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5CW7kxeH8_W",
        "outputId": "a9f5ca9c-45de-4945-8623-9fa1e6c664e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    4.3s finished\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
        "rf_pipe = bienc_ltr_feats >> pt.ltr.apply_learned_model(rf)\n",
        "rf_pipe.fit(train_topics, qrels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "iHJYe-qNH_vy"
      },
      "outputs": [],
      "source": [
        "train_request = fastrank.TrainRequest.coordinate_ascent()\n",
        "params = train_request.params\n",
        "params.init_random = True\n",
        "params.normalize = True\n",
        "params.seed = 1234567\n",
        "ca_pipe = bienc_ltr_feats >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
        "ca_pipe.fit(train_topics, qrels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ziwEUjoIZJL",
        "outputId": "7567a4e1-a533-4df4-bf48-9a287c8e892b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's ndcg@20: 0.586793\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's ndcg@20: 0.702743\n",
            "[3]\tvalid_0's ndcg@20: 0.707713\n",
            "[4]\tvalid_0's ndcg@20: 0.676361\n",
            "[5]\tvalid_0's ndcg@20: 0.700949\n",
            "[6]\tvalid_0's ndcg@20: 0.683647\n",
            "[7]\tvalid_0's ndcg@20: 0.699805\n",
            "[8]\tvalid_0's ndcg@20: 0.696416\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's ndcg@20: 0.707713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        }
      ],
      "source": [
        "lmart_l = lgb.LGBMRanker(\n",
        "    task=\"train\",\n",
        "    silent=False,\n",
        "    min_data_in_leaf=1,\n",
        "    min_sum_hessian_in_leaf=1,\n",
        "    max_bin=255,\n",
        "    num_leaves=31,\n",
        "    objective=\"lambdarank\",\n",
        "    metric=\"ndcg\",\n",
        "    ndcg_eval_at=[10],\n",
        "    ndcg_at=[10],\n",
        "    eval_at=[10],\n",
        "    learning_rate= .1,\n",
        "    importance_type=\"gain\",\n",
        "    num_iterations=100,\n",
        "    early_stopping_rounds=5\n",
        ")\n",
        "lmart_x_pipe.fit(train_topics, qrels, valid_topics, qrels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEjXz64vXnPl"
      },
      "source": [
        "## Task 4.3 Re-run the experiment here using the new features! (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "S8G6xjfRIbw1",
        "outputId": "93d2aa31-dc49-4ced-c5f0-4ff43574d77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.3s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           name       map      ndcg  ndcg_cut_10        mrt\n",
              "0          bm25  0.760650  0.823841     0.740103   3.380184\n",
              "1         tfidf  0.760820  0.826136     0.740142   3.268419\n",
              "2       ca_pipe  0.766710  0.830632     0.745759  34.894478\n",
              "3       rf_pipe  0.817961  0.886145     0.825310  39.911935\n",
              "4  lmart_x_pipe  0.730713  0.810350     0.713836  25.324495"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-baa74b30-338f-44a0-8213-e0c4c2f3fc0e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <th>mrt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bm25</td>\n",
              "      <td>0.760650</td>\n",
              "      <td>0.823841</td>\n",
              "      <td>0.740103</td>\n",
              "      <td>3.380184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tfidf</td>\n",
              "      <td>0.760820</td>\n",
              "      <td>0.826136</td>\n",
              "      <td>0.740142</td>\n",
              "      <td>3.268419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ca_pipe</td>\n",
              "      <td>0.766710</td>\n",
              "      <td>0.830632</td>\n",
              "      <td>0.745759</td>\n",
              "      <td>34.894478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rf_pipe</td>\n",
              "      <td>0.817961</td>\n",
              "      <td>0.886145</td>\n",
              "      <td>0.825310</td>\n",
              "      <td>39.911935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lmart_x_pipe</td>\n",
              "      <td>0.730713</td>\n",
              "      <td>0.810350</td>\n",
              "      <td>0.713836</td>\n",
              "      <td>25.324495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baa74b30-338f-44a0-8213-e0c4c2f3fc0e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-baa74b30-338f-44a0-8213-e0c4c2f3fc0e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-baa74b30-338f-44a0-8213-e0c4c2f3fc0e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "pt.Experiment(\n",
        "    [bm25, tfidf, ca_pipe, rf_pipe, lmart_x_pipe],\n",
        "    query_df,\n",
        "    qrels,\n",
        "    names = ['bm25', 'tfidf', 'ca_pipe', 'rf_pipe', 'lmart_x_pipe'],\n",
        "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4GHjMzoXnPm"
      },
      "source": [
        "# _Optional_: Evaluating the different models (20 points total; this is part 2)\n",
        "\n",
        "How much training does the model actually need to recognize relevance? Would one epoch be enough? What if we did 10? or 100? (100 might be too many for Great Lakes limits...). In this **optional part**, we'll describe a series of steps you can take to explore this part!\n",
        " \n",
        "The instructions in Part 1 had you update that notebook to save the model after each epoch and then generate relevance predictions for each, saving those to a file. In Part 2, we'll load those files and compare the performance:\n",
        " \n",
        "Here's what you need to do:\n",
        "* Using the code from the blocks above, create new version of the test data DataFrame that have predictions from each trained bi-encoder model. (i.e., you should have predictions from the model trained on one epoch worth of data, predictions from the model trained on two epochs, etc.)\n",
        "* Retrain each L2R model using each of these new features, using just one feature at a time. This should give you (number of L2R models) * (number of different-epoch-trained-biencoder-models) worth of results.\n",
        "* Create a line plot where\n",
        "  * the x-axis is the number of epochs the bi-encoder model was trained\n",
        "  * the y-axis is NDCG_cut_10\n",
        "  * there are different lines for each L2R model (with different colors/hues for each model)\n",
        " \n",
        "This plot should show you how much the bi-encoder's training time influences the scores. Compare that with the F1 performance plot you produced for Part 1. Does increasing F1 performance lead to increasing NDCG@10? How many epochs do you think you need to train to maximize performance?\n",
        "\n",
        "**TODO:** For full credit, submit a separate doc/pdf with the plots from Parts 1 and 2 and a short paragraph describing your observations on the performance (see the questions above)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}